<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Chaos万有引力</title>
    <description>We are interested in Deep Learning, Machine Learning, Causality, Reinforcement Learning, and any other information or technologies about AI.</description>
    <link>http://localhost:4000/</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Thu, 13 Oct 2022 22:50:46 +0800</pubDate>
    <lastBuildDate>Thu, 13 Oct 2022 22:50:46 +0800</lastBuildDate>
    <generator>Jekyll v3.8.7</generator>
    
      <item>
        <title>如何抓取一个微信公众号的所有文章（Python）下篇</title>
        <description>&lt;p&gt;声明：基本步骤和核心方法均参考[1]，[2]，细节有大不同，这篇着重于如何将抓取到的文章用markdown的格式保存下来。&lt;/p&gt;

&lt;h4 id=&quot;1-上篇中已经抓到了公众号的所有文章的题目和链接下篇直接读入&quot;&gt;1. 上篇中已经抓到了公众号的所有文章的题目和链接，下篇直接读入：&lt;/h4&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pandas&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;newspaper&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Article&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;html2text&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ht&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;yaml&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;time&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;requests&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;bs4&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BeautifulSoup&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;os&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;tomd&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;re&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;chaos-gravity.yaml&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;r&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;file_data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;yaml&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;safe_load&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;file_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;get_headers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;headers&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;Cookie&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'cookie'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;User-Agent&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'user-agent'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;headers&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_option&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'max_colwidth'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;article_list&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'article_list2.csv'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;encoding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'GB18030'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;headers&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;get_headers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;download_images&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;soup&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;content&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dir_name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;assets/images/&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;/&quot;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;isdir&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dir_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mkdir&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dir_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cnt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;images&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;content&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find_all&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;img&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;images&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;img_src&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'data-src'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;img_type&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'data-type'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;img_name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;{0:d}.{1:s}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cnt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;img_type&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;img_type&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'png'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;cnt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;file_path&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;assets/images/{0:s}/{1:s}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;img_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exists&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;file_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;file_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'wb'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;response&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;requests&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;url&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;img_src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;block&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;response&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iter_content&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1024&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
                    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;block&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                        &lt;span class=&quot;nb&quot;&gt;file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;write&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;block&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                        &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;tag&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;soup&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;new_tag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'span'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;tag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;string&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;![](assets/images/{0:s}/{1:s})&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;img_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;replace_with&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;download_videos&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;soup&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;content&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dir_name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;assets/videos/&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;/&quot;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;isdir&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dir_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mkdir&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dir_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;videos&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;video&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;videos&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;video_src&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;video&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'data-src'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

            &lt;span class=&quot;n&quot;&gt;tag&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;soup&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;new_tag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'span'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;tag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;string&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;[此处是视频]({0:s})&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;video_src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;video&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;replace_with&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;for_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;content&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;content&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find_all&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;ol&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find_all&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;li&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;tag&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;soup&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;new_tag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'span'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;tag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;string&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;{0:d}. {1:s}&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;replace_with&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;for_code2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;content&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;content&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find_all&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;class_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;code-snippet__fix code-snippet__js&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find_all&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;code&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;tag&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;soup&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;new_tag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'code'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;tag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;string&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;replace_with&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;            
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;for_code&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;content&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;content&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find_all&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;class_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;code-snippet__fix code-snippet__js&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;tag&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;soup&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;new_tag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'code'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;string&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;length&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find_all&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;code&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find_all&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;code&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;string&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;string&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;extract&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;tag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;string&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;string&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;replace_with&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;article_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iterrows&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;create_time&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;strftime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;%Y-%m-%d&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;localtime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;create_time&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;url&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'link'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;replace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;\/&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;article&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;requests&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;headers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;headers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;article&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;status_code&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;html&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;article&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# for_code 
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;html&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;html&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;replace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&amp;lt;br  /&amp;gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;soup&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BeautifulSoup&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;html&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'html.parser'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;content&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;soup&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'img-content'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;#有些文章已经被删除了，就提取不到content了
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;content&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;title&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;content&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;class_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'rich_media_title'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;strip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# \/:*?&quot;&amp;lt;&amp;gt;|这些字符不能作为文件名或者文件夹名
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;replace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'\/'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'-'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;replace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\\&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'-'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;replace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'-'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;replace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'|'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'-'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;replace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;:&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;_&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;replace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;?&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;_&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;replace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;*&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;_&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;replace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&amp;lt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;_&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;replace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&amp;gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;_&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'.md'&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;copyright&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;content&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;class_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'wx_tap_link js_wx_tap_highlight rich_media_meta icon_appmsg_tag appmsg_title_tag weui-wa-hotarea'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;except&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;copyright&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;author&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;content&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;class_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'wx_tap_link js_wx_tap_highlight rich_media_meta_link weui-wa-hotarea'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;except&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;author&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;content&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;class_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;rich_media_meta rich_media_meta_text&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot; &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;blog_name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;content&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;class_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'profile_nickname'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;blog_sign&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;content&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;div&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;div&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;div&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find_all&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'p'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;span&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;soup&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;html&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;body&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find_all&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'script'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'publish_time'&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;publish_time&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;document.getElementById&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;{e(&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;,&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;,&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;content&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'meta_content'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;decompose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;download_images&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;soup&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;content&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;brs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;content&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find_all&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'br'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;brs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;br&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;brs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;br&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;decompose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;for_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;content&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;for_code2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;content&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;mdText&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;content&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;replace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&amp;lt;br/&amp;gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;''&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;replace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&amp;lt;/code&amp;gt;&amp;lt;code&amp;gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;replace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;lt;/code&amp;gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&amp;lt;/code&amp;gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;replace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&amp;lt;code&amp;gt;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&amp;lt;code&amp;gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# 代码部分自动换行
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;mdText&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tomd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Tomd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mdText&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;markdown&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# 改格式转错的地方
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;mdText&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mdText&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;replace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'# &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;            &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'## '&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;replace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;# &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;mdText&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sub&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;r'\n[\- ]+[ ]+\n```'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;```&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mdText&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'w'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;encoding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'utf8'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;nb&quot;&gt;file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;write&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mdText&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;代码有点长，调起来费了九牛二虎之力，这里试的是微信公众号的文章转markdown，可能和其他网页不是那么匹配，主要还是要去熟悉soup的使用方法，并坚持将匹配错误的地方各个击破。&lt;/p&gt;

&lt;p&gt;没有实现的功能：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;视频没办法处理&lt;/li&gt;
  &lt;li&gt;不能百分百准确，文字和图谱还是偶有缺失，缺失率小于1%&lt;/li&gt;
  &lt;li&gt;有些文字格式会跑掉&lt;/li&gt;
  &lt;li&gt;列表不能准确转换，太懒了，懒得写了&lt;/li&gt;
  &lt;li&gt;基础版，特殊格式字符什么的，无法正确转换，需要自己开发&lt;/li&gt;
  &lt;li&gt;转换完扔需要校验，无法自动调校图片大小，需要手动&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;上面代码主要实现的功能：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;代码模块可以成功换行了&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;图片可以自动下载保存到本地并赋予链接&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;一些匹配错误的地方做了校正&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

</description>
        <pubDate>Tue, 11 Oct 2022 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/%E5%A6%82%E4%BD%95%E6%8A%93%E5%8F%96%E4%B8%80%E4%B8%AA%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7%E7%9A%84%E6%89%80%E6%9C%89%E6%96%87%E7%AB%A0-Python-%E4%B8%8B%E7%AF%87/</link>
        <guid isPermaLink="true">http://localhost:4000/%E5%A6%82%E4%BD%95%E6%8A%93%E5%8F%96%E4%B8%80%E4%B8%AA%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7%E7%9A%84%E6%89%80%E6%9C%89%E6%96%87%E7%AB%A0-Python-%E4%B8%8B%E7%AF%87/</guid>
        
        <category>Crawler</category>
        
        
        <category>Tools</category>
        
      </item>
    
      <item>
        <title>如何抓取一个微信公众号的所有文章（Python）上篇</title>
        <description>&lt;p&gt;声明：基本步骤和核心方法均参考[1]，未做诸多更改，但是细节上可能因为微信自己做了更新，爬取细节很不同，另外就是加入了一些文本处理的操作。&lt;/p&gt;

&lt;h4 id=&quot;1-注册微信公众号---新建图文消息---超链接---右键下拉菜单点击检查---检查页面中最上面选network---在左边的搜索公众号文章搜索自己想要的公众号并选中---观察右边的检查页面会发现下方列表中新增了一个以appmsg开头的项目点击这个appmsg开头的项目然后在检查页面的右方选择headersheaders-下面有个generalgeneral里面有个request-url-&quot;&gt;1. 注册微信公众号 -&amp;gt; 新建图文消息 -&amp;gt; 超链接  -&amp;gt; 右键下拉菜单点击“检查” -&amp;gt; 检查页面中最上面选“Network” -&amp;gt; 在左边的搜索公众号文章搜索自己想要的公众号，并选中 -&amp;gt; 观察右边的检查页面，会发现下方列表中新增了一个以“appmsg”开头的项目，点击这个“appmsg”开头的项目，然后在检查页面的右方选择“Headers”。”Headers” 下面有个”General”，”General”里面有个”Request URL“ ：&lt;/h4&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;https://mp.weixin.qq.com/cgi-bin/appmsgpublish?sub=list&amp;amp;amp;search_field=null&amp;amp;amp;begin=0&amp;amp;amp;count=5&amp;amp;amp;query=&amp;amp;amp;type=101_1&amp;amp;amp;free_publish_type=1&amp;amp;amp;sub_action=list_ex&amp;amp;amp;token=221080036&amp;amp;amp;lang=zh_CN&amp;amp;amp;f=json&amp;amp;amp;ajax=1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;2-解析request-url&quot;&gt;2. 解析”Request URL“:&lt;/h4&gt;

&lt;p&gt;该链接分三部分：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;https://mp.weixin.qq.com/cgi-bin/appmsg 请求的基础部分&lt;/li&gt;
  &lt;li&gt;?action=list 常用于动态网站，实现不同的参数值而生成不同的页面或者返回不同的结果&lt;/li&gt;
  &lt;li&gt;&amp;amp;search_field=null&amp;amp;begin=0&amp;amp;count=5&amp;amp;query=&amp;amp;type=101_1&amp;amp;free_publish_type=1&amp;amp;sub_action=list_ex&amp;amp;token=221080036&amp;amp;lang=zh_CN&amp;amp;f=json&amp;amp;ajax=1 设置各种参数&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;3-获取cookie和user-agent&quot;&gt;3. 获取Cookie和User-Agent&lt;/h4&gt;

&lt;p&gt;直接用Python的Requests库访问该url，并不能正常获得结果。原因在于利用网页版微信公众号后台插入超链接时，是登录状态，而用python直接访问时是未登录状态。因此，需要手动获取访问时的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Cookie&lt;/code&gt;和&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;User-Agent&lt;/code&gt;,在用Python的Requests库进行访问时将其传入&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;headers&lt;/code&gt;参数。这里将公众号标识符&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;fakeid&lt;/code&gt;以及&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;token&lt;/code&gt;参数保存在了一个yaml文件中，方便爬取时加载。这些都可以在右边的检查页面中搜到：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;fakeid: Mzg5...
token: 22...
user-agent: Mozilla/5.0 ...
cookie: ua_id=9gk3jF5RLFPEru...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;用yaml包读取参数&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;yaml&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;chaos-gravity.yaml&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;r&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;as&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;file_data&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;yaml&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;safe_load&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;file_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;headers&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Cookie&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'cookie'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;User-Agent&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'user-agent'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;4-设置请求参数生成url&quot;&gt;4. 设置请求参数，生成url&lt;/h4&gt;

&lt;p&gt;对照自己找到的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Request URL&lt;/code&gt;改下面的参数：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# 请求参数
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;https://mp.weixin.qq.com/cgi-bin/appmsgpublish&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;begin&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;0&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;sub&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;list&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;search_field&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;null&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;sub_action&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;list_ex&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;begin&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;begin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;free_publish_type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;count&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;5&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;fakeid&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'fakeid'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;101_1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;token&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'token'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;lang&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;zh_CN&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;f&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;json&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;ajax&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;1&quot;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;5-抓取文章题目作者链接及其他有用信息并保存成csv文件&quot;&gt;5. 抓取文章题目，作者，链接及其他有用信息并保存成csv文件&lt;/h4&gt;

&lt;p&gt;这部分需要一行一行代码校验，防止微信公众号改了规则，下面代码和参考[1]就很不同了，而不同的主要原因来自于细节上的更改。&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;column_name&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;aid,appmsgid,author_name,title,cover_img,digest,link,create_time&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;article_list_path&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;article_list.csv&quot;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;article_list_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;a&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;as&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;write&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;column_name&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;while&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;begin&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;begin&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;begin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# 随机暂停几秒，避免过快的请求导致过快的被查到
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sleep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;resp&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;requests&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;headers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;headers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;verify&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# 微信流量控制, 退出
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;resp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;json&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'base_resp'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'ret'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;200013&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;frequencey control, stop at {}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;begin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sleep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3600&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;continue&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;        &lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;0&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;total_count&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;resp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;json&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'publish_page'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'total_count'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;We have &quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tatal_count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot; articles.&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;publish_list&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;resp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;json&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'publish_page'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'publish_list'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# 如果返回的内容中为空则结束
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;publish_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;all ariticle parsed&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;publish&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;publish_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;publish&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;publish&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'publish_info'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;replace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;true&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;True&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;replace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;false&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;False&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'appmsgex'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;info&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&quot;{}&quot;,&quot;{}&quot;,&quot;{}&quot;,&quot;{}&quot;,&quot;{}&quot;,&quot;{}&quot;,&quot;{}&quot;,&quot;{}&quot;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;publish&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;aid&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]),&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;\
&lt;span class=&quot;err&quot;&gt;                &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;publish&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'appmsgid'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]),&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;publish&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'author_name'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]),&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;\
&lt;span class=&quot;err&quot;&gt;                &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;publish&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'title'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;replace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;replace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;,&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;\
&lt;span class=&quot;err&quot;&gt;                &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;publish&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'cover'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]),&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;publish&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'digest'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;replace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;replace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;,&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;\
&lt;span class=&quot;err&quot;&gt;                &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;publish&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'link'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]),&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;publish&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'create_time'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;article_list_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;a&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;as&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;            &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;write&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;info&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;info&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;,&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;---------------------------------------------------------------------------------&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# 翻页
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;6-完整代码get_wechart_article_listpy&quot;&gt;6. 完整代码get_wechart_article_list.py：&lt;/h4&gt;

&lt;p&gt;注意：因为内容是保存成csv档，所以如果标题和内容简介中有逗好，都替换成了分号。&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;yaml&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;requests&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;def&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_headers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;headers&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Cookie&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'cookie'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;User-Agent&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'user-agent'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;headers&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;def&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;https://mp.weixin.qq.com/cgi-bin/appmsgpublish&quot;&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;begin&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;0&quot;&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;sub&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;list&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;search_field&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;null&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;sub_action&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;list_ex&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;begin&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;begin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;free_publish_type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;count&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;5&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;fakeid&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'fakeid'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;101_1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;token&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'token'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;lang&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;zh_CN&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;f&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;json&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;ajax&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;1&quot;&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;def&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_article_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;headers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;column_name&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;aid,appmsgid,author_name,title,cover_img,digest,link,create_time&quot;&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;article_list_path&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;article_list.csv&quot;&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;article_list_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;a&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;as&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;write&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;column_name&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;while&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;begin&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;begin&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;begin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# 随机暂停几秒，避免过快的请求导致过快的被查到
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sleep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;resp&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;requests&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;headers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;headers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;verify&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# 微信流量控制, 退出
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;resp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;json&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'base_resp'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'ret'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;200013&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;            &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;frequencey control, stop at {}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;begin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;            &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sleep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3600&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;            &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;continue&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;        &lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;0&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;            &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;total_count&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;resp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;json&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'publish_page'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'total_count'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;            &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;We have &quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tatal_count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot; articles.&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;publish_list&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;resp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;json&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'publish_page'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'publish_list'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# 如果返回的内容中为空则结束
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;publish_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;            &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;all ariticle parsed&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;            &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;publish&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;publish_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;            &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;publish&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;publish&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'publish_info'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;replace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;true&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;True&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;replace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;false&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;False&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'appmsgex'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;            &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;info&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&quot;{}&quot;,&quot;{}&quot;,&quot;{}&quot;,&quot;{}&quot;,&quot;{}&quot;,&quot;{}&quot;,&quot;{}&quot;,&quot;{}&quot;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;publish&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;aid&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]),&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;\
&lt;span class=&quot;err&quot;&gt;                &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;publish&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'appmsgid'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]),&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;publish&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'author_name'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]),&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;\
&lt;span class=&quot;err&quot;&gt;                &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;publish&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'title'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;replace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;replace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;,&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;\
&lt;span class=&quot;err&quot;&gt;                &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;publish&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'cover'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]),&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;publish&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'digest'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;replace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;replace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;,&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;\
&lt;span class=&quot;err&quot;&gt;                &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;publish&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'link'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]),&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;publish&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'create_time'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;            &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;article_list_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;a&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;as&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;                &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;write&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;info&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;            &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;info&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;,&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;            &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;---------------------------------------------------------------------------------&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;err&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# 翻页
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;def&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;chaos-gravity.yaml&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;r&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;as&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;file_data&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;yaml&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;safe_load&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;file_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;headers&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_headers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_article_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;headers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__name__&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'__main__'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这篇抓链接，下篇抓文章。&lt;/p&gt;

&lt;p&gt;参考链接：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;https://zhuanlan.zhihu.com/p/379062852&lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Thu, 28 Jul 2022 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/%E5%A6%82%E4%BD%95%E6%8A%93%E5%8F%96%E4%B8%80%E4%B8%AA%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7%E7%9A%84%E6%89%80%E6%9C%89%E6%96%87%E7%AB%A0-Python-%E4%B8%8A%E7%AF%87/</link>
        <guid isPermaLink="true">http://localhost:4000/%E5%A6%82%E4%BD%95%E6%8A%93%E5%8F%96%E4%B8%80%E4%B8%AA%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7%E7%9A%84%E6%89%80%E6%9C%89%E6%96%87%E7%AB%A0-Python-%E4%B8%8A%E7%AF%87/</guid>
        
        <category>Crawler</category>
        
        
        <category>Tools</category>
        
      </item>
    
      <item>
        <title>钢琴曲转谱（Solo Piano Transcription）</title>
        <description>&lt;p&gt;​    今天来看一篇钢琴琴谱翻译的文章，出自ByteDance字节跳动，Giant-Piano（&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg5ODIwMTUxNw==&amp;amp;mid=2247484584&amp;amp;idx=1&amp;amp;sn=55cea90737a5ed57577e078f4e8df908&amp;amp;chksm=c067666af710ef7c5819fcd93c1f0657a1e896db43647c734dc4945a803be9afc6528debf205&amp;amp;scene=21#wechat_redirect&quot;&gt;GiantMIDI-Piano：字节跳动发布的大型古典钢琴乐MIDI数据集&lt;/a&gt;）采用的转谱模型就是这个：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/piano_trans_paper_2020/0.png&quot; alt=&quot;AltText&quot; width=&quot;75%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;​    两个相关的源代码地址：&lt;/p&gt;

&lt;p&gt;琴转谱：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;https://github.com/bytedance/piano_transcription
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;数据集相关：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;https://github.com/bytedance/GiantMIDI-Piano
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;​    曲转谱（Automatic Music Transcription（AMT））就是把钢琴曲（音频）转换成电子乐谱（Musical Instrument Digital Interface（MIDI））。这个课题的相关工作是比较少的，毕竟乍一看乍一想没啥商业价值。咱读这篇，就当好玩吧，毕竟，谁不热爱音乐呢？这次除了会解读论文，还会解析代码。&lt;/p&gt;

&lt;p&gt;​    AMT是音乐信息提取（Music Information Retrieval（MIR））中关联基于音频的音乐理解和基于符号的音乐理解的桥梁。AMT有几个关键的应用，包括乐谱跟踪（Score Following），音频与乐谱对位（audio to score alignment），以及根据曲谱分离出曲子（score-informed source separation  ）。而工业界，AMT可以用来做音乐类的教育软件，可以为创作者将弹的曲子翻译成谱子，可以将音频信息转换成符号信息等等。&lt;/p&gt;

&lt;p&gt;​    这篇只做钢琴曲的转谱。包括识别音调（pitch），按下琴键（onset），松开琴键（offset），速度（velocity）等信息。钢琴曲转谱并不简单，之前也有各种各样的尝试，这里就不仔细展开说了，感兴趣的看论文原文。我们直接说一说之前的工作都有哪些不足（以前的工作的不足，就是这个工作的动机）：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;之前的曲转谱呢，是把曲子切割成一个一个小段（frames），然后再来标记每个frame的特征，比如是onset还是offset。这样的话翻译的精度就被frame的长度限制住了。&lt;/li&gt;
  &lt;li&gt;之前的工作多用一个frame来标记onset或者offset，但是其实类似onset的行为造成的影响，可能会持续不止一个frames，另外如果只用一个frame来标记onset或者offset，模型训练会对曲谱错位非常敏感。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;接下来就是看针对这两个不足，新方法都做了哪些改进。&lt;/p&gt;

&lt;p&gt;先简略介绍些概念：&lt;/p&gt;

&lt;h4 id=&quot;1-梅尔频谱以下内容来自参考1&quot;&gt;1. 梅尔频谱（以下内容来自参考[1]）&lt;/h4&gt;

&lt;p&gt;​    音频信号是时域信号。人对声音的分辨力根据频率的不同而不同，较容易分辨低频信号，比如人很容易可以分辨500Hz和1000Hz的信号，但是却不那么容易分辨10000Hz和10500Hz，尽管两组信号的频域距离是一样的。梅尔频谱是说对频率做一个映射，相对拉大低频信号的距离，缩小高频信号的距离，使得人对他们的分辨能力和他们的距离能匹配上。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/piano_trans_paper_2020/1.jpg&quot; alt=&quot;AltText&quot; width=&quot;35%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;​    具体公式和具体工程实现请参考[2]：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/piano_trans_paper_2020/2.png&quot; alt=&quot;AltText&quot; width=&quot;30%&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;2-frame-wise-翻译系统&quot;&gt;2. Frame-wise 翻译系统&lt;/h4&gt;

&lt;p&gt;​    在进行曲转谱的最开始，会把曲子先切割成frames，然后再将每个frame转成频域信号，再转换成梅尔频谱，因此最后输入是：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/piano_trans_paper_2020/3.png&quot; alt=&quot;AltText&quot; width=&quot;13%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;T是frames的数量，F是梅尔频带的数量。通常来说，这个任务的label，target是下面这样的：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/piano_trans_paper_2020/4.png&quot; alt=&quot;AltText&quot; width=&quot;17%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;T依然还是frames的数量，而K则是琴键的数量，比如88。而网络的输出可以表示为：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/piano_trans_paper_2020/5.png&quot; alt=&quot;AltText&quot; width=&quot;13%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;那么损失函数则可以用如下方式计算：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/piano_trans_paper_2020/6.png&quot; alt=&quot;AltText&quot; width=&quot;43%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;其中：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/piano_trans_paper_2020/7.png&quot; alt=&quot;AltText&quot; width=&quot;43%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在frame-wise翻译系统里，要判断的是每一帧里，每个琴键的状态，是有发声还是没有发声。然后说一说这种方法的缺点：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;这种翻译方式，如果要转成普通琴谱的样子还需要有精确的后期工作&lt;/li&gt;
  &lt;li&gt;另外这种方式不能准确的预测onsets，而onsets又恰恰包含了大量信息&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;3-onsets-and-frames-翻译系统&quot;&gt;3. Onsets and Frames 翻译系统&lt;/h4&gt;

&lt;p&gt;​	为了解决上面的问题，那么自然就提出了预测onsets和offsets的双目标系统。也有人onsets和frames双目标系统，也就是说既输出onsets也输出上面frame-wise输出的结果。所以损失函数是：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/piano_trans_paper_2020/8.png&quot; alt=&quot;AltText&quot; width=&quot;20%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;其中：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/piano_trans_paper_2020/9.png&quot; alt=&quot;AltText&quot; width=&quot;35%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这个方法也依然又缺陷：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;精度受frame长短限制&lt;/li&gt;
  &lt;li&gt;而onsets和frames仅用二进制0，1来表达状态，其实也不够精确&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;方法&quot;&gt;方法&lt;/h3&gt;

&lt;p&gt;​	这篇文章的方法自然要解决之前方法的缺陷，首先看下面这张图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/piano_trans_paper_2020/10.png&quot; alt=&quot;AltText&quot; width=&quot;60%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;​	红线表示真正onset的时间，我们上节提到的onsets &amp;amp; frames方法仅仅标记了onset发生的那个frame。但这样是不准确的，因为这样无法表达一次onset的行为会对每个frame造成什么样的影响。ADSR则会识别onsets和offsets，onset造成影响的frames都会被标注成1。但ADSR这种方法会使音频波形变得模糊，会使offset的识别变得相对困难，而第一种方法会对onset和offset没有严格对其这种错误非常敏感。而为了解决上面两个问题，Attack&amp;amp;decay则用连续值来标记onset。那最后一个缺点就是，以上方法都没有标记onset的具体时间。用以上的方法，onset可以是一个frame种的任何时间，而如果onset如果恰好在两个frame的边界线上，那么target怎么标记都好像不太对，而如果为了解决这个问题去缩小frame的尺寸，一方面会增加计算量，另外一个方面是之前的问题依然存在。接下来就讲这篇文章提出的方法：&lt;/p&gt;

&lt;h4 id=&quot;regress-onset-and-offset-times&quot;&gt;Regress Onset and Offset Times&lt;/h4&gt;

&lt;p&gt;​	这篇文章的译谱方法会输出具体的onset和offset的时间，这个想法受YOLO（You Only Look Once）启发，在YOLO里，图片会被切割为很多个grids，需要预测grid和object的距离。而这个任务的目标则是输出每个frame离自己最近的onset和offset的距离，如上图种最后一行所示。这边会对目标做一个变换：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/piano_trans_paper_2020/11.png&quot; alt=&quot;AltText&quot; width=&quot;30%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;i是一个相对位置，J是控制锋度的变量，变换后，target大概长下面这样：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/piano_trans_paper_2020/12.png&quot; alt=&quot;AltText&quot; width=&quot;60%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;regression的意思也就在这里了。损失函数：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/piano_trans_paper_2020/13.png&quot; alt=&quot;AltText&quot; width=&quot;40%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;G是targets，R是预测结果。&lt;/p&gt;

&lt;h4 id=&quot;velocity-estimation&quot;&gt;Velocity Estimation&lt;/h4&gt;

&lt;p&gt;​	声音的三个属性指音量，音调和音色，音色不用判断，因为这个任务专识别钢琴，音调不同notes音调不同，所以还剩下音量，但是velocity这个单词我反复查看都是速度的意思，而文章的意思又明显指音量，即声音的大小。所以我猜可能是作者用错了词？或者这里面有我什么没看懂的关窍。总之先按音量来理解：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/piano_trans_paper_2020/14.png&quot; alt=&quot;AltText&quot; width=&quot;50%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;vel下标指的是velocity，on下标指的是onset，I指targets，P指ground truth。因为onsets的过程包含了更多关于音量的信息，因此音量的判断只用onsets的部分来判断，就不用offsets的部分来判断了。&lt;/p&gt;

&lt;h4 id=&quot;entire-system&quot;&gt;Entire System&lt;/h4&gt;

&lt;p&gt;​	整个系统的网络框架如下图所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/piano_trans_paper_2020/15.png&quot; alt=&quot;AltText&quot; width=&quot;50%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;首先音频信号会切割成frames，每个frame再分别做梅尔频谱变化，输入则是做过频谱变换的数据，模型分四个部分，最左边做velocity regression，结果会接着用来加入做onset regression，原因是声音的高低有助于onset的判断，如果声音低，那么系统会消耗更多的注意力去侦测onset，这和人会耗费更多注意力在音量低的部分是一样的（这里就有点不懂这个逻辑了，比如怎么就能提高对系统对音量低的部分的注意力呢？），另外加入做onset regression的还有一个frequency dimension。onset regression和offset regression的结果会加入做frame-wise classification。更细节的模型框架见下图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/piano_trans_paper_2020/16.png&quot; alt=&quot;AltText&quot; width=&quot;70%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;总的损失函数：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/piano_trans_paper_2020/17.png&quot; alt=&quot;AltText&quot; width=&quot;30%&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;推理&quot;&gt;推理&lt;/h4&gt;

&lt;p&gt;​	推理的时候首先把曲子切割成frames，转换成梅尔频谱，再输入模型，得到velocity，onset，offset，frame-wised的结果，再转换成正规的曲谱。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/piano_trans_paper_2020/18.png&quot; alt=&quot;AltText&quot; width=&quot;60%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;​	上图展示了如果计算精确的onset和offset时间的算法，A，B，C是三个相邻的frames的中心时间，B是那个被预测最有可能是onset所在的frame的中心时间。首先对所有frame单个分析，如果一个frame它的预测为onset的值超过了一定数，则去判断周边的两个都比他低，如果是的，那么则去找一个G点，使得AG与CG是以GI为轴对称的。那么上图中BH就是要求的答案，如果A所在的frame是onset的概率小于C所在的frame，则：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/piano_trans_paper_2020/19.png&quot; alt=&quot;AltText&quot; width=&quot;30%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;否则：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/piano_trans_paper_2020/20.png&quot; alt=&quot;AltText&quot; width=&quot;30%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;文中给了推导过程，这里就不细说了，感兴趣的可以验证一下。推理过程的算法如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/piano_trans_paper_2020/21.png&quot; alt=&quot;AltText&quot; width=&quot;50%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;首先，onset和offset是成对出现的，算法中的10和11即计算BH的两个公式，P是frame-wise的输出。这个方法无法识别长度小于4个frames的onsets，但现实中这种情况也几乎不会发生。此外音量的值由[0,1]区间转至[0,128]区间。&lt;/p&gt;

&lt;h4 id=&quot;sustain-pedal-transcription&quot;&gt;Sustain Pedal Transcription&lt;/h4&gt;

&lt;p&gt;​	踏板对演奏的影响是很大的，按下时，延音踏板通过将所有制音器从琴弦上移开来维持钢琴上的所有阻尼琴弦，并允许琴弦自由振动。 正在播放的所有音符将继续发声，直到松开踏板。之前的钢琴译谱系统，有些没有做踏板状态的识别，有些做了呢，又没做曲调的识别。因此这篇文章还做了延音踏板译谱的工作，这个和曲调的模型是分开的，分开可以获得更好的效果，最后踏板的值在[0,128]之间。如果小于64，那么表示踏板没有开启，如果大于64，则表示踏板开启了。这样做其实是粗糙的，因为踏板中还有一些特殊技术，比如half pedals，这里是不识别的。踏板可以被当作一个琴键，损失函数和之前的其他琴键是一样的，也一样会有onset，offset和frame-wise结果：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/piano_trans_paper_2020/22.png&quot; alt=&quot;AltText&quot; width=&quot;40%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;总的损失函数：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/piano_trans_paper_2020/23.png&quot; alt=&quot;AltText&quot; width=&quot;34%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;精确时间的计算算法如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/piano_trans_paper_2020/24.png&quot; alt=&quot;AltText&quot; width=&quot;50%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;和琴键的onset，offset判断模式是不一样的，如果pedal onset的概率大于一定值，且比上一帧的概率大，那么就会被判断成是进行了onset。offset则是如果offset的概率大于一定值，或者frame-wise的值小于一定值，则判断为offset的帧，offset和onset是成对的。精确的时间的计算方法和琴键的onset，offset的计算方法是一样的（这里感觉琴键和pedal的具体时间的算法的写法有点问题，没有体现onset和offset的成对属性）。&lt;/p&gt;

&lt;h3 id=&quot;实验&quot;&gt;实验&lt;/h3&gt;

&lt;h4 id=&quot;数据&quot;&gt;数据&lt;/h4&gt;

&lt;p&gt;​	数据集用的是MAESTRO dataset V2.0.0，包含200h钢琴独奏录音和对应的MIDI琴谱，时间精度约3ms。&lt;/p&gt;

&lt;h4 id=&quot;预处理&quot;&gt;预处理&lt;/h4&gt;

&lt;p&gt;​	所有音乐转为单声道，并将采样频率同步成16kHz，然后将其切割成10s的片段。然后将每个片段通过短时傅里叶变换（Hann窗口大小是2048）转成频谱。&lt;/p&gt;

&lt;p&gt;参考：&lt;/p&gt;

&lt;p&gt;[1]. Leland Roberts, Understanding the Mel Spectrogram, medium, 2020&lt;/p&gt;

&lt;p&gt;[2]. BeichenLiu.Polaris，语音特征提取: 看懂梅尔语谱图(Mel-spectrogram)、梅尔倒频系数(MFCCs)的原理，2021&lt;/p&gt;
</description>
        <pubDate>Tue, 28 Jun 2022 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/%E9%92%A2%E7%90%B4%E6%9B%B2%E8%BD%AC%E8%B0%B1-Solo-Piano-Transcription/</link>
        <guid isPermaLink="true">http://localhost:4000/%E9%92%A2%E7%90%B4%E6%9B%B2%E8%BD%AC%E8%B0%B1-Solo-Piano-Transcription/</guid>
        
        <category>GiantMIDI-Piano</category>
        
        
        <category>Audio</category>
        
        <category>Representation Learning</category>
        
      </item>
    
      <item>
        <title>UC Berkeley非监督学习--Implicit Models -- GANs (上)</title>
        <description>&lt;p&gt;    翻译整理一下UC Berkeley非监督学习的课程。这篇翻译第五六讲Implicit Models – GANs。分三篇：上，中，下。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Implicit Models -- GANs (上)/1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;    这个课程总共十二讲，官方链接：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;https://sites.google.com/view/berkeley-cs294-158-sp20/home
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;    目前已整理过：&lt;/p&gt;

&lt;p&gt;        Lecture 1：&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg5ODIwMTUxNw==&amp;amp;mid=2247484985&amp;amp;idx=1&amp;amp;sn=87564039ce87c9618bbd7fd68cb83339&amp;amp;chksm=c06764fbf710eded7815eeeec344ab1b1807534664d18973ca9a3d566d8b7f1d37d62e2f2e8c&amp;amp;scene=21#wechat_redirect&quot;&gt;UC Berkeley非监督学习–介绍&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;        Lecture 2：&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg5ODIwMTUxNw==&amp;amp;mid=2247485197&amp;amp;idx=1&amp;amp;sn=7c51b8ec0198f627d562fbf0dc0ddb1c&amp;amp;chksm=c06765cff710ecd97a813a6550272be127ac5ea844764a08b2d33646c84e539fc45f212dfe0a&amp;amp;scene=21#wechat_redirect&quot;&gt;UC Berkeley非监督学习–自回归模型&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;        Lecture 3：&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg5ODIwMTUxNw==&amp;amp;mid=2247485497&amp;amp;idx=1&amp;amp;sn=2e073fa7a62a656f0a145ad5380a8fe8&amp;amp;chksm=c0676afbf710e3ed62622aee58404b13fd1175145afb21112efd6732f88003413b3127b1d031&amp;amp;scene=21#wechat_redirect&quot;&gt;UC Berkeley非监督学习–流模型（Flow Models）&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;        Lecture 4：&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg5ODIwMTUxNw==&amp;amp;mid=2247486320&amp;amp;idx=1&amp;amp;sn=12deb99b51522dcad015e53bd6e92716&amp;amp;chksm=c06769b2f710e0a4a71fb778ab7fc6314cf9de907670456e7a148e956156bce3424694a1bb6b&amp;amp;scene=21#wechat_redirect&quot;&gt;UC Berkeley非监督学习–Latent Variable Models – VAE（潜变量模型–VAE）&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;        Lecture 7：&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg5ODIwMTUxNw==&amp;amp;mid=2247484457&amp;amp;idx=1&amp;amp;sn=745a486cd18e1f8b0e7e6c80c325a4ef&amp;amp;chksm=c06766ebf710effd996dc3ba4fa7c6cf8827fef00f09fce3d439c7e951c0e8b1ff987b8b0326&amp;amp;scene=21#wechat_redirect&quot;&gt;自监督学习（Self Supervised Learning）&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    这篇讲Implicit Models，很多是GANs，内容有点丰富，占了两个Lectures，因此这次会分上中下三篇。整理完这两个，剩下的8，9，10，11，12接下来可能不会整理，也可能会慢慢整理。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Implicit Models -- GANs (上)/2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这是发明GAN的人。这样看效果图，GAN确实很强啊。大家可以在B站或者油管搜BigGAN的视频，看看变换潜变量可以达到的不同效果。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Implicit Models -- GANs (上)/3.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;2018年，一个人从github上下载了些代码，用GAN训练了模型并生成了上面这幅图，卖了$432500，&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Implicit Models -- GANs (上)/4.png&quot; style=&quot;zoom:50%;&quot; /&gt;，所以，看完这篇吧，让我们离财富自由更近一点。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;图像生成的目标：&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;可以理解图片中的内容&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;可以完成从一幅图到另外一幅图的丝滑转换。&lt;/li&gt;
  &lt;li&gt;可以生成和样本相似却又不同的图。&lt;/li&gt;
  &lt;li&gt;可以通过调整潜变量生成有不同特征的图（样本图中没有的特征）。 &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Implicit Models -- GANs (上)/5.png&quot; style=&quot;zoom:10%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;    Implicit Models要做的也是，先生成一个潜变量z，再通过模型把潜变量转换成图片。但他训练模型的方式和VAE以及Flow Models是不一样的，它通过评估生成的图片的品质来优化模型。&lt;/p&gt;

&lt;p&gt;Implicit Models的基本逻辑：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Implicit Models -- GANs (上)/6.png&quot; style=&quot;zoom: 80%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;翻译一下是：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;需要样本图片pdata&lt;/li&gt;
  &lt;li&gt;需要可以生成图片的q，然后生成一堆图片pmodel&lt;/li&gt;
  &lt;li&gt;需要一个可以比较pmodel和pdata的差异的模型D&lt;/li&gt;
  &lt;li&gt;获得更好的Φ的方式是努力去缩小pmodel和pdata的差异&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;GAN的第一篇文章发表于2014年&lt;/strong&gt;：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Implicit Models -- GANs (上)/7.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;来看损失函数：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Implicit Models -- GANs (上)/8.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;G是生成器（z-&amp;gt;x），D是分辨器（分辨输入是G生成的，还是训练样本中的）。D越是确信输入是训练集中的样本，则输出的值越大。D和G存在一个博弈关系，G的目标就是尽量让D(G(z))的输出趋近于1，而D的目标是尽量让D(x)的输出趋近于1，D(G(z))的输出趋于0。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Implicit Models -- GANs (上)/9.png&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Implicit Models -- GANs (上)/10.png&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;大家可以去下面的网址去观察一下gan训练的可视化效果，还挺有意思的：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;https://poloclub.github.io/ganlab/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Implicit Models -- GANs (上)/11.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;    上面这张图是2014年GAN可以做到的效果，右边黄框里的是样本图片，其他是生成的图片，可以发现，当时GAN就可以很好的生成和样本图片近似的图片，但是还不完美，还有很多似是而非的图片产生。&lt;/p&gt;

&lt;p&gt;    接下来看如何评估GANs模型，到现在生成模型的评估依然是一个问题，而GANs不像之前的生成模型，我们可以用极大似然值来评估，另外，生成图片的优劣其实是一种主观判断。&lt;/p&gt;

&lt;p&gt;   &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;评估GANs模型：&lt;/strong&gt;
&lt;strong&gt;1.  Parzen-Window density estimator / Kernel Density Estimator (KDE)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Implicit Models -- GANs (上)/12.png&quot; style=&quot;zoom: 33%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这是2006年被提出来的一个概念，网上解释很多，这里就不细说了，详细可以看参考[1]。上面公式中K是窗函数，判断x和xi的距离是不是在一定区间内，K也可以是高斯函数等。KDE要输出密度值，越多样本在x周边，给出的密度值越大。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Implicit Models -- GANs (上)/13.png&quot; style=&quot;zoom: 67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;当h设置不同的值时，出来的效果也很不同，用这个方法得选一下窗口值的大小。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Implicit Models -- GANs (上)/14.png&quot; style=&quot;zoom: 50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;2014年的GAN有用这个方法来评估模型，但事实上这个评估方式更适合低维度的数据，不太适合高维度的数据。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Implicit Models -- GANs (上)/15.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;上图实验数据，用于6*6，36维的数据评估，可以发现这个评估方法的效果不是很好，而且和k-means这些方法的比较，也可以发现，也许这个方法只能很好的评估聚类效果，而不是生成效果。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2.  Inception Score&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Implicit Models -- GANs (上)/16.png&quot; style=&quot;zoom: 67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;看一下Inception Score的基本想法和方法：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt; 绕过高维密度估计&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;一个好的生成网络可以生成多种多样不同语义图片&lt;/li&gt;
  &lt;li&gt;给定生成图片，图片中的事物可以被明确地分辨出来，p(y|x)应该是低熵的&lt;/li&gt;
  &lt;li&gt;通过调整潜变量，可以生成含有不同事物的图片，p(y)应该是高熵的。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;基于以上考虑，Inception Score公式如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Implicit Models -- GANs (上)/17.png&quot; style=&quot;zoom: 67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;值越高越好。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Implicit Models -- GANs (上)/18.png&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;由上面的实验结果可以发现，Inception Score确实可以很好的区分真实图片和生成图片，评估生成图片的质量。但这个方法也有缺点，比如说，背景信息，边边角角的生成质量被忽略了，另外就是如果在生成数据的时候，针对Inception Model可以识别的类，一个类生成一个，那么最后就可以获得很好的Inception Score。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3.  Fréchet Inception Distance&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Implicit Models -- GANs (上)/19.png&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Fréchet Inception Distance （FID）的基本想法和方法：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt; Inception Score不够优秀，包括无法评估生成图片的细节优劣，另外如果你生成有方，模型可识别的类型每样生成一个，只要生成的质量不是太差，都能获得很高的Inception Score&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;FID可以更多的分辨细节上的优劣。&lt;/li&gt;
  &lt;li&gt;实现方法就是把生成的图片转换成特征向量，feature embedding，即不是用判断物种类别的结果，而是用判断类别前生成的特征向量来判断生成样本的好坏。同样是用生成样本和训练样本去做比较，比较特征向量的均值和协方差。&lt;/li&gt;
  &lt;li&gt;值越低越好&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Implicit Models -- GANs (上)/20.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Implicit Models -- GANs (上)/21.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;IND是越低越好，FID是越高越好，通过上面几幅图比较，明显FID更优秀。&lt;/p&gt;

&lt;p&gt;现在我们来总结一下GAN的基本特征：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt; 可以快速生成，随机生成一个潜变量，然后通过训练好的生成网络，即可产生图片&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;没有推理网络，只有一个生成网络，和一个判断图片是不是生成的网络，不需要像VAE一样再有一个把图片转换成潜变量的网络（GAN变种可以有）&lt;/li&gt;
  &lt;li&gt;目标函数直接明了。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;一些原理：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;    接下来看一些GAN背后的原理。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1.  Bayes-Optimal Discriminator&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;    如果已知训练数据的样本分布和生成数据的样本分布，最佳分辨器是什么？&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Implicit Models -- GANs (上)/22.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;    由此可知，当训练样本分布和生成样本分布都已知的情况下，最佳分辨器是可以直接求出来的。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Implicit Models -- GANs (上)/23.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;如果用最佳分辨器来训练生成网络呢？&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Implicit Models -- GANs (上)/24.png&quot; style=&quot;zoom: 80%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;由于分辨器已经用了最佳，V肯定是越小越好，按上面的公式，V可以分解为一个常量项和两个KL项，两个KL项大于等于0，则V可能的最小值就是-log(4)，而优化生成模型的时候，其实我们只需要优化两个KL项，即JSD，使其最小化即可。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2.  Jensen-Shannon Divergence （JSD）&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;
&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Implicit Models -- GANs (上)/25.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;    我们来看一下JSD和其他方法的比较，如上图所示，原始数据的分布如左边第一幅图，我们现在要用一个高斯函数来拟合这个分布，KLD，MMD，JSD的拟合结果分别用圆线展示出来了，会发现，KLD想尽量囊括所有数据的特征，MMD会倾向于最强的分布，但是又会被小的分布影响到。而JSD则是比MMD更倾向于最强分布，忽略了小的分布。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Implicit Models -- GANs (上)/26.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;    上图展示了分别用Maximum likelihood和Reverse KL拟合的结果，可以发现前者为折中拟合，后者是二选一拟合。而JSD其实介于这两个方法之间，但是更接近Reverse KL。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Implicit Models -- GANs (上)/27.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;左边是Maximum likelihood，中间是Reverse KL，右边是JSD，可以发现，JSD其实是介于前两者之间的一个方法。&lt;/p&gt;

&lt;p&gt;那么究竟哪种拟合效果更好，更值得追求呢？目前来看，如果是想保留更多的信息，比如压缩图片，那么第一种可能更好，如果是图像生成，需要尽可能清晰地获取特征，那么可能Reverse KL，JSD会更好。更好的方法当然是尽可能避免用一个高斯函数去拟合复杂的数据分布。但是高纬度的数据复杂度是极高的，我们不太可能用我们的肉眼，包括一些数据分析工具来知道，我们应该用什么样复杂度的模型去拟合，因此，在选择优化模型的方法时，还是得多注意一点，尽量避免Mode collapse，或者效能上的损失。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3.  Mode Collapse&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Implicit Models -- GANs (上)/28.png&quot; style=&quot;zoom:90%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;比如上图这种情况，数据分布如最右边的小图所示，仍然是用高斯分布去拟合，会发现，得到的结果会随着训练进程一直在变。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3.  Avoiding Saturation&lt;/strong&gt; &lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Implicit Models -- GANs (上)/29.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;来看，可不可以先训练D呢？以及，如果我们一开始只优化D，会出现什么问题。&lt;/p&gt;

&lt;p&gt;    答案是可以先训练D，而且可以训练出来不错的D。但是如果把D先优化好，再来优化G，G会没办法优化。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Implicit Models -- GANs (上)/30.png&quot; style=&quot;zoom: 67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Implicit Models -- GANs (上)/31.png&quot; style=&quot;zoom:33%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Implicit Models -- GANs (上)/32.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;当D可以很好地识别训练图和生成图后，D是一个很好的二分类分类器，假设D那个时候是一个sigmoid函数。那么它求导以后如右下角所示，当x是假图的时候梯度趋近0。因此G不会被优化。&lt;/p&gt;

&lt;p&gt;但这个问题有办法可以解决：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Implicit Models -- GANs (上)/33.png&quot; style=&quot;zoom: 67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;优化G的时候加个负号，最小化变最大化。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Implicit Models -- GANs (上)/34.png&quot; style=&quot;zoom: 50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Implicit Models -- GANs (上)/35.png&quot; style=&quot;zoom: 80%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;D优化后，当输入x是生成图时，梯度趋近于-1。问题解决。&lt;/p&gt;

&lt;p&gt;[1] kiyoxi，Parzen window 密度估计——一种非参数概率密度函数估计方法，知乎，2022&lt;/p&gt;

</description>
        <pubDate>Tue, 10 May 2022 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/UC-Berkeley%E9%9D%9E%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-Implicit-Models-GANs-(%E4%B8%8A)/</link>
        <guid isPermaLink="true">http://localhost:4000/UC-Berkeley%E9%9D%9E%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-Implicit-Models-GANs-(%E4%B8%8A)/</guid>
        
        <category>UC Berkeley CS294-158</category>
        
        
        <category>CV</category>
        
        <category>Unsupervised Learning</category>
        
        <category>Generative Model</category>
        
      </item>
    
      <item>
        <title>UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）</title>
        <description>&lt;p&gt;    翻译整理一下UC Berkeley非监督学习的课程。这篇翻译第四讲&lt;strong&gt;Latent Variable Models – VAE&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;    这个课程总共十二讲，官方链接：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;https://sites.google.com/view/berkeley-cs294-158-sp20/home
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;    目前已整理过：&lt;/p&gt;

&lt;p&gt;        Lecture 1：&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg5ODIwMTUxNw==&amp;amp;mid=2247484985&amp;amp;idx=1&amp;amp;sn=87564039ce87c9618bbd7fd68cb83339&amp;amp;chksm=c06764fbf710eded7815eeeec344ab1b1807534664d18973ca9a3d566d8b7f1d37d62e2f2e8c&amp;amp;scene=21#wechat_redirect&quot;&gt;UC Berkeley非监督学习–介绍&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;        Lecture 2：&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg5ODIwMTUxNw==&amp;amp;mid=2247485197&amp;amp;idx=1&amp;amp;sn=7c51b8ec0198f627d562fbf0dc0ddb1c&amp;amp;chksm=c06765cff710ecd97a813a6550272be127ac5ea844764a08b2d33646c84e539fc45f212dfe0a&amp;amp;scene=21#wechat_redirect&quot;&gt;UC Berkeley非监督学习–自回归模型&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;        Lecture 3：&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg5ODIwMTUxNw==&amp;amp;mid=2247485497&amp;amp;idx=1&amp;amp;sn=2e073fa7a62a656f0a145ad5380a8fe8&amp;amp;chksm=c0676afbf710e3ed62622aee58404b13fd1175145afb21112efd6732f88003413b3127b1d031&amp;amp;scene=21#wechat_redirect&quot;&gt;UC Berkeley非监督学习–流模型（Flow Models）&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;        Lecture 7：&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg5ODIwMTUxNw==&amp;amp;mid=2247484457&amp;amp;idx=1&amp;amp;sn=745a486cd18e1f8b0e7e6c80c325a4ef&amp;amp;chksm=c06766ebf710effd996dc3ba4fa7c6cf8827fef00f09fce3d439c7e951c0e8b1ff987b8b0326&amp;amp;scene=21#wechat_redirect&quot;&gt;自监督学习（Self Supervised Learning）&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    之前的自回归模型是这样生成的，有了x1之后，生成x2，两个都有了之后生成x3。这样的依赖关系，让生成图片特别慢，要生成一个28*28的图片，就得把模型跑28*28次。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/2.png&quot; style=&quot;zoom: 25%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;    流模型虽然也用了潜变量来生成，但是流模型的潜变量和样本变量是一对一的，也就是说要生成的图片有多大，那么潜变量就得有多大。潜变量在流模型中不是一个更抽象的存在。这一讲中的研究，就会用更抽象的潜变量来生成，如果要生成一个超级大的图，不一定需要一个很大的潜变量。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/3.png&quot; style=&quot;zoom:25%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;    下面这种图，其实可以被简短的语言描述，三只柯基，每只是什么颜色，有什么与众不同的特征，背景是什么样子的，有些什么，通常你把这些信息告诉一个画家，画家便可以为你创作出一幅画来。因此生成图，其实并不一定需要一个和图差不多大小的潜变量，一个很小的向量，也许就可以。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/4.png&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;    理论上，潜变量是可以有明确的意义的，比如你通过潜变量来生成人像图，向量第一个值可以代表发色，第二个值代表眼睛的大小，第三个值代表肤色，总之可以让潜变量中的每个值有明确的意义，使得图像生成可以随人心所欲。虽然现在主流生成模型很少去定义潜变量的意义，但这种生成方式正被积极研究。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/5.png&quot; style=&quot;zoom: 25%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;    接下来这一篇，都在讲怎么基于潜变量，生成样本。       &lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/6.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;    若z中的每个值都服从伯努利分布，那么p(x|z)实质上也是服从伯努利分布。&lt;/p&gt;

&lt;p&gt;    这篇讨论的内容包括：&lt;/p&gt;

&lt;p&gt;   &lt;strong&gt;1. 采样/生成：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/7.png&quot; style=&quot;zoom: 33%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;    &lt;strong&gt;2.  模型评估，极大似然函数：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/8.png&quot; style=&quot;zoom: 33%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/9.png&quot; style=&quot;zoom: 50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;上面的公式就是训练目标。&lt;/p&gt;

&lt;p&gt;   &lt;strong&gt;3. 数据表现(representation)：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/10.png&quot; style=&quot;zoom: 33%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;    样本转换为计算机更容易理解的抽象表达。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;模型训练&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;    模型训练的目标：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/11.png&quot; style=&quot;zoom: 67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;    分两种情况：&lt;/p&gt;

&lt;p&gt;    一种情况是z的可取值就那么几个，几十个或者几百个，总之不算多，比如下面这种情况，z只有三种可能，且每种可能发生的概率是三分之一：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/12.png&quot; style=&quot;zoom: 67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;    假设p(x|z)服从多元高斯分布（Multivariate Gaussian Distribution），那么则有如下训练目标：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/13.png&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;    看一个可以用以上方法解的实例：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/14.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;    通过对训练数据的观察，很容易发现样本集分三个群，有遵循高斯分布的感觉，不过这个图画得不特别明显，可以点再细些，看看是不是每个群离中心点越远，样本越稀疏。如果用上面的假设来训练，最后可以很好地生成类似的样本分布图。当然也可以做其他假设，可以尝试不同假设，然后取效果最好的那个使用。&lt;/p&gt;

&lt;p&gt;    第二种情况是如果z可以有很多很多不同的值呢？&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/15.png&quot; style=&quot;zoom: 67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/16.png&quot; style=&quot;zoom:33%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;    一种方法是可以采用对z进行采样。z的概率就由采样的状况决定了。但这种方式有一个很大的缺点，如果z的可能性太多，那么z的采样效率会很低很低，比如z是一个长度为100的二值向量，那么z就有2的100次方个可能性，如果对z进行全域均匀采样，每个样本x匹配到对应的z的概率就是2的一百次方分之一。 就现在的计算能力来看，就是没什么可能能让样本x匹配到对应的z。&lt;/p&gt;

&lt;p&gt;    毫无疑问，均匀采样是不可行的，那么要怎么采样呢？接下来了解一下&lt;strong&gt;重要性采样（Importance Sampling）。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;    如果z服从pz分布，那么函数f(z)的期望值如何计算：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/17.png&quot; style=&quot;zoom: 25%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;    计算这个可能会有两个问题，一个问题是pz这个分布过于特殊或者复杂，或者其他什么原因，让你没有办法正常采样。另一个问题是说z的可能性太多，一般的采样方式效率非常非常低，采样出来的z可以提供的信息非常少。这篇遇到的是第二个问题。&lt;/p&gt;

&lt;p&gt;    为了解决这些问题，可以进行一些转换：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/18.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;既然在分布pz上采样不可行，那么自然要找到适合采样的分布q，那么f(z)的期望值(z服从pz)问题则转换成了求(pz(z)/q(z))f(z)的期望值，z服从q分布。  &lt;/p&gt;

&lt;p&gt;    那么训练目标也更新了：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/19.png&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;    现在的问题在于，如何求这个分布q。理论上，可以如下方式求：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/20.png&quot; style=&quot;zoom: 50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;    但分母恰是我们本来要求的问题。所以这个方法不可行。求精确的不行，那么求个大概也许可行，比如可以假设q(z)服从高斯分布：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/21.png&quot; style=&quot;zoom:25%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;而接下来要做的就是求这个高斯分布的参数，使得q(z)尽可能接近：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/22.png&quot; style=&quot;zoom:33%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/23.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;但是这个方法呢，也有一个问题，就是对每个样本都得求它对应的z的q分布。而过程又是一致的。因此，可不可以直接交给神经网络来呢？与其对每个样本都来求一次它对应的z的分布，不如求一个一般的神经网络，使得输入样本后便能输出对应的z的分布。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Amortized formulation:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/24.png&quot; style=&quot;zoom: 50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;（PS：终于绕到这个公式了，以前觉得理所应当就应该这样的，没想到原来是这么九曲回肠地绕过来的。）&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/25.png&quot; style=&quot;zoom:50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;如上图所示，生成模型实实在在想做的事情是图中实线所示的事情，但是为了求得能完成实线功能的模型，得把实现虚线功能的模型也求了。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Importance Weighted AutoEncoder (IWAE)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;目标是最大化：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/26.png&quot; style=&quot;zoom: 67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;而因为z的采样问题，同时需要最小化&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/27.png&quot; style=&quot;zoom:50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;所以要做的就是最大化公式一减去公式二的值&lt;/p&gt;

&lt;p&gt;定义wi和Lk如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/28.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;log是凸函数，根据Jensen不等式，先log再期望小于等于先期望再log。&lt;/p&gt;

&lt;p&gt;    有研究人员在2015年证明，Lk是一直小于等于logp(x)的，k的数值越大，越接近logp(x)，当k趋近于正无穷时，Lk = logp(x)。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/29.png&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;证明如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/30.png&quot; style=&quot;zoom: 67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Variational Lower Bound (VLB)/ Evidence Lower Bound (ELBO)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/31.png&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;以上推理过程如果想把不等式转换成等式，那么不能单单只优化θ，还得优化Φ，反复不断优化θ和Φ，获得更好的q分布和p分布。当q是最佳时：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/32.jpeg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;再有一种写法：&lt;/p&gt;

&lt;p&gt;在上面的写法中，如果q不是最佳，那么求得的期望值就会小于等于logp(x)。那么差多少呢？&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/33.png&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/34.png&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这种写法和上面那种就是多了后面KL散度的部分，第一种写法我们知道期望值与logp(x)有差，这一种方法我们可以知道差的就是KL散度部分。当KL散度求值结果为0时，那么logp(x)就和后面的期望值一致了。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/35.png&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;而在优化的过程中，KL散度是不需要被考虑的，VLB的部分才是需要计算的：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/36.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;优化算法可以用梯度下降的方式，那么首先我们得求梯度：&lt;/p&gt;

&lt;p&gt;课程中介绍了两种方式，这里我们还参考了另外一个课程[3]，和一篇博客[4]，首先，当我们要微分的变量存在于分布中时，我们用likelihood ratio gradient estimator：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/37.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;当我们要微分的变量存在于待求的期望的函数中时，我们用pathwise derivative：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/38.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;关于likelihood ratio gradient estimator可以看参考[4]，这里就贴一下推导公式：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/39.png&quot; style=&quot;zoom: 50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;上面公式是我们要求梯度的函数，而现实实验中，我们通常没有办法直接得到分布函数，能得到的是一堆样本，因此：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/40.png&quot; style=&quot;zoom: 50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;梯度公式的求导过程如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/41.png&quot; style=&quot;zoom:50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;likelihood ratio gradient estimator在绝大多数场景中都可以使用，而pathwise derivative在一些场景中效果会比likelihood ratio gradient estimator好很多，即使只有极小量数据也能取得好的结果。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/42.png&quot; style=&quot;zoom: 33%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;    我们要用的其实是θ，但要得到好的θ，得同时交叉优化Φ。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/43.png&quot; style=&quot;zoom: 33%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;极大似然估计（likelihood ratio）：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/44.png&quot; style=&quot;zoom: 50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/45.png&quot; style=&quot;zoom: 33%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/46.png&quot; style=&quot;zoom: 33%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/47.png&quot; style=&quot;zoom:33%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/48.png&quot; style=&quot;zoom:33%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/49.png&quot; style=&quot;zoom: 50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;pathwise derivative （这个方法是有前提的，q得遵循高斯分布，p也是，但两个是不一样的参数）：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/50.png&quot; style=&quot;zoom: 67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;来看VAE的生成数字的效果图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/51.png&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/52.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;VAE是将概率图模型的思想和AE（Auto Encoder）的结合体。[6]&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;接下来看几个典型的VAE模型的变种：&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt; VQ-VAE&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/53.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;**&lt;/em&gt;发表于2017年，几乎没有被关注，大家的注意力都在GAN那里。直到两年后第二篇文章发表，效果非常好，两篇文章才引起了关注。&lt;/p&gt;

&lt;p&gt;这个算法就不细讲了，感兴趣的可以看看参考[5]和论文原文，上图中带箭头的线条，蓝色是推理，红色是反向传播。损失函数中有一个比较重要的概念是Straight-Through Estimator，前向传播时，sg符号无用，忽略掉即可，反向传播时，sg标记的部分不进行调整，保持不变。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/54.png&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;VQ-VAE重建图片的能力如上图所示，左边是原图，右边是重构的图片。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/55.png&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;VQ-VAE图像生成的效果，如上图所示。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2. VQ-VAE 2.0&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/56.png&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这里就直接摘参考[5]的文字描述了：&lt;/p&gt;

&lt;p&gt;    “这是VQ-VAE的升级版, 可以生成非常清晰的高分辨率图片。主要变化就是把VQ-VAE的encoder和decoder进行了分层, bottom层对local feature进行建模, top层对global feature进行建模; 为了让top层能更有效地提取global信息, 在网络中加入了self attention。除此之外, 在prior上进行采样的时候, 考虑到autoregressive的sample会累积误差, 即如果x1出现了一点误差, 那么x2|x1的误差会更大, 因此加入了rejection sampling, 即生成某类的图片后, 通过一个classifier判断一下生成的图片像不像这个类的sample, 如果不像就弃掉. 文章效果很惊艳, 但是理论上没有特别大的改进。”&lt;/p&gt;

&lt;p&gt;那接下来看看惊艳的效果：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/57.png&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/58.png&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;​	可以和BigGAN比了，右边的图是BigGAN生成的，左边的是VQ-VAE生成的。可以发现，左边的图其实更多样化一点。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/59.png&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/60.png&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;3. z和decoder&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;​	到目前为止，所用的decoder都特别简单（p(x|z)遵循的分布都是简单的），因此没有办法携带大量信息，基本上有用的信息都会压缩到潜变量z里。&lt;/p&gt;

&lt;p&gt;    前面推导过：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/61.png&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;因此：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/62.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;VLB最大可以是logp(x)，如果KL部分是0。&lt;/p&gt;

&lt;p&gt;如果p(x|z) = pdata(x)，则有：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/63.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这个时候，训练模型q(z|x)会去接近p(z)，那么z中就没有什么有用信息了。p(x|z) = pdata(x)要怎么做到呢？即decoder包含了所有信息。因此，如果z中信息越少，decoder越强大，信息越多，那么VLB越接近理想值。因此许多工作都往这个方向去努力了，但是这样的话，就没有办法很好地进行生成了。这个问题在许多工作中有被描述：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/64.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;为了解决这个问题，需要弱化decoder：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/65.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;其中，第二个是VLAE，这个方法是想让z去掌握全局信息，而decoder去掌握细节信息，decoder用的是浅层PixelCNN，适合挖掘局部细节信息。但也有很多方法想让z不仅掌握粗粒度的全局信息，还想让他表达细节，这里是一些动态训练的方法：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/66.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;4. Disentanglement: Beta VAE&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/67.png&quot; style=&quot;zoom: 50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;​	与VAE不同的地方就是损失函数KL散度那部分，前面加了一个beta，当beta是1的时候，就是标准的VAE，当beta大于1的时候，z的信息丰富度会降低，但是解纠缠的能力会提高。解纠缠的能力可以理解为representation的能力，即z中的值可以表达特定的意义的能力，比如生成人脸，我们会希望z中的值有特定意义，比如脸的宽度，眼睛的大小等，这样可以通过调整z中某个值来变化人脸的局部特征。当beta变大时，会让训练出来的结果更趋近于高斯分布，而每个高斯分布的参数又相互独立，因此可以更好的解纠缠。下图就展现了，用这种方法训练出的可以通过调整z中的值来生成不同肤色，年龄，性别的人像的模型。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/68.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;其他&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1. Variational Dequantization (Flow++)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;    在训练这类模型的时候，有一个问题，就是图像数据（像素值，0-255）是离散数据，而我们要输出的概率密度函数，是连续的。如果不对数据进行处理，那么出来的结果可能是整数点上的概率密度值都很高（比如3，78，255），但是他们周边就很低（比如3.1，77.9，244.7），因此需要对输入的数据做一些处理，这个处理叫解量化（Dequantization）。也有其他一些方法，比如Uniform Dequantization：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/69.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;但由于VAE会用Jensen’s inequality做一个近似转换，这样一来，噪音项又被消掉了。所以不管用。&lt;/p&gt;

&lt;p&gt;还有一种方法是，flow++中的Variational Dequantization：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/70.png&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;添加一个可训练的噪音项，效果如下图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/71.png&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong style=&quot;outline: 0px;&quot;&gt;
&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2. Mutual Information Estimation &lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;    互信息（Mutual Information）：&lt;strong style=&quot;outline: 0px;&quot;&gt;
&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/72.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;​	首先来回顾一下什么是信息熵，可以参考&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg5ODIwMTUxNw==&amp;amp;mid=2247484059&amp;amp;idx=1&amp;amp;sn=422a4565edeba1b9087615ed0f72a59a&amp;amp;chksm=c0676059f710e94fe65e01143f15585b9ef1e7f46187f30a40fc5b9d6dd9c5bc38bddb2cf115&amp;amp;scene=21#wechat_redirect&quot;&gt;Cross Entropy Loss，&lt;/a&gt;H(X)是X的信息熵（信息量的期望值，即表达这个事件需要的编码的位数的期望值）：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/73.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;可以发现，互信息可以用来表达两个变量的依赖程度。&lt;/p&gt;

&lt;p&gt;互信息的应用场景：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/74.png&quot; style=&quot;zoom:50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这些可能之后会提到。VAE中会用到的是，计算z和x的互信息值：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--Latent Variable Models -- VAE（潜变量模型--VAE）/75.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;第三行(logp(z&lt;/td&gt;
      &lt;td&gt;x)-logq(z&lt;/td&gt;
      &lt;td&gt;x))构成KL散度。为了提高z和x的相关度，我们需要做的是最大化公式最后一行的内容。&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong style=&quot;outline: 0px;&quot;&gt;
&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong style=&quot;outline: 0px;&quot;&gt;
&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;声明：文中所有图片和原理均来自课程和参考。同时所有参考都是推荐扩展阅读的内容。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;参考：&lt;/p&gt;

&lt;p&gt;[1] Jeremy Zhang, Importance Sampling Introduction, 2019&lt;/p&gt;

&lt;p&gt;[2] Bo’s Blog，Importance Weighted Autoencoders and Jackknife Methods，2019&lt;/p&gt;

&lt;p&gt;[3] Katerina Fragkiadaki, ‘Pathwise derivatives, DDPG,
Multigoal RL’, in Deep Reinforcement Learning and Control, Carnegie Mellon&lt;/p&gt;

&lt;p&gt;[4] Timvieira, The likelihood-ratio gradient，Graduate Descent，2019，https://timvieira.github.io/blog/post/2019/04/20/the-likelihood-ratio-gradient/&lt;/p&gt;

&lt;p&gt;[5] Elijha，VQ-VAE解读，知乎，2019&lt;/p&gt;

&lt;p&gt;[6] 大象, VAE系解纠缠：从VAE到βVAE，再到β-TCVAE, 知乎，2019&lt;/p&gt;

&lt;p&gt; &lt;/p&gt;

</description>
        <pubDate>Fri, 06 May 2022 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/UC-Berkeley%E9%9D%9E%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-Latent-Variable-Models-VAE-%E6%BD%9C%E5%8F%98%E9%87%8F%E6%A8%A1%E5%9E%8B-VAE/</link>
        <guid isPermaLink="true">http://localhost:4000/UC-Berkeley%E9%9D%9E%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-Latent-Variable-Models-VAE-%E6%BD%9C%E5%8F%98%E9%87%8F%E6%A8%A1%E5%9E%8B-VAE/</guid>
        
        <category>UC Berkeley CS294-158</category>
        
        
        <category>CV</category>
        
        <category>Unsupervised Learning</category>
        
        <category>Generative Model</category>
        
      </item>
    
      <item>
        <title>UC Berkeley非监督学习--流模型（Flow Models）</title>
        <description>&lt;p&gt;    翻译整理一下UC Berkeley非监督学习的课程。这篇翻译第三讲&lt;strong&gt;Flow Models，流模型&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--流模型（Flow Models）/1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;    这个课程总共十二讲，官方链接：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;https://sites.google.com/view/berkeley-cs294-158-sp20/home
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;    目前已整理过：&lt;/p&gt;

&lt;p&gt;        Lecture 1：&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg5ODIwMTUxNw==&amp;amp;mid=2247484985&amp;amp;idx=1&amp;amp;sn=87564039ce87c9618bbd7fd68cb83339&amp;amp;chksm=c06764fbf710eded7815eeeec344ab1b1807534664d18973ca9a3d566d8b7f1d37d62e2f2e8c&amp;amp;scene=21#wechat_redirect&quot;&gt;UC Berkeley非监督学习–介绍&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;        Lecture 2：&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg5ODIwMTUxNw==&amp;amp;mid=2247485197&amp;amp;idx=1&amp;amp;sn=7c51b8ec0198f627d562fbf0dc0ddb1c&amp;amp;chksm=c06765cff710ecd97a813a6550272be127ac5ea844764a08b2d33646c84e539fc45f212dfe0a&amp;amp;scene=21#wechat_redirect&quot;&gt;UC Berkeley非监督学习–自回归模型&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;        Lecture 7：&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg5ODIwMTUxNw==&amp;amp;mid=2247484457&amp;amp;idx=1&amp;amp;sn=745a486cd18e1f8b0e7e6c80c325a4ef&amp;amp;chksm=c06766ebf710effd996dc3ba4fa7c6cf8827fef00f09fce3d439c7e951c0e8b1ff987b8b0326&amp;amp;scene=21#wechat_redirect&quot;&gt;自监督学习（Self Supervised Learning）&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1. 1-D&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;    先看一维空间。样本都是一个值，生成也只需要生成一个值。 &lt;/p&gt;

&lt;p&gt;    上一篇讲自回归模型，一直在求概率分布函数，这一节我们来求概率密度函数。本质上他们是一回事，只是前者是用来求离散值的概率，后者是用来求连续值的概率。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--流模型（Flow Models）/2.png&quot; style=&quot;zoom: 67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;    如果我们要预测的值是个连续值，而不是离散值，那么理论上一般情况下任何一个特定值发生的概率都趋近于0。所以如果是连续值，那么通常求的是在某个区间发生的概率，p(x)是概率密度函数，如上图右边公式求的是x在[a, b]这个区间的概率。概率密度函数一般满足以下条件：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--流模型（Flow Models）/3.png&quot; style=&quot;zoom: 50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;    那怎么基于概率密度函数产生极大似然函数：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--流模型（Flow Models）/4.png&quot; style=&quot;zoom: 67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--流模型（Flow Models）/5.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;    求解时可以假设概率密度函数服从高斯分布。&lt;/p&gt;

&lt;p&gt;    但是很可惜，上面那种方法对高维数据，效果很差。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--流模型（Flow Models）/6.png&quot; style=&quot;zoom: 50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;    流模型中输出不再是概率密度函数，而是一个&lt;strong&gt;潜在变量&lt;/strong&gt;（&lt;strong&gt;latent variables&lt;/strong&gt;），我还是喜欢理解为特征向量。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--流模型（Flow Models）/7.png&quot; style=&quot;zoom: 50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;再通过改变潜在向量来让计算机创造图片。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--流模型（Flow Models）/8.png&quot; style=&quot;zoom:50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;那么如何训练模型：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--流模型（Flow Models）/9.png&quot; style=&quot;zoom: 33%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;由于p(x|z)是很难求出来的，因为z可以是无穷的，所以只能换个思路：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--流模型（Flow Models）/10.png&quot; style=&quot;zoom: 67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;概率密度函数的特性，全域积分为1，根据这个特性：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--流模型（Flow Models）/11.png&quot; style=&quot;zoom: 25%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--流模型（Flow Models）/12.png&quot; style=&quot;zoom:33%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;上面公式中&lt;strong&gt;f &lt;/strong&gt;得是可微且可逆的。可逆才可以根据潜在变量进行生成：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--流模型（Flow Models）/13.png&quot; style=&quot;zoom:25%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;极大似然函数则可以转换为：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--流模型（Flow Models）/14.png&quot; style=&quot;zoom: 67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;来看z遵循不同分布的训练结果(这里讨论的z只有一个值，即在一维空间中即可定位)：&lt;/p&gt;

&lt;p&gt;比如均匀分布(Uniform)：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--流模型（Flow Models）/15.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;比如Beta(5,5):&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--流模型（Flow Models）/16.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;比如高斯分布：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--流模型（Flow Models）/17.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;那除了训练模型，有没有其他方法可以得到x-&amp;gt;z的函数，当x和z都只有一个变量的时候，是可以的。比如下面这个方法&lt;strong&gt;Cumulative Density Functio&lt;/strong&gt;&lt;strong&gt;n (CDF)：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--流模型（Flow Models）/18.png&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这样的话，z服从均匀分布，这种转换和采样的方式和上一个Lecture中Hostogram采样的方式理论上是一致的，只是CDF用于连续值，Hostogram用于离散值：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--流模型（Flow Models）/19.png&quot; style=&quot;zoom: 80%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;可以发现CDF可以把任何分布通过一个可逆可微函数转换成均匀分布，而可逆可微函数的逆函数依然可逆可微，因此均匀分布可以被转换成任意其他的分布。因此CDF可以实现将一个分布通过两次转换转换成任意其他分布的功能。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--流模型（Flow Models）/20.png&quot; style=&quot;zoom: 50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;以上是z是单变量的情况，如果z是一个长度为2的向量呢？长度为n呢？&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1. 2-D&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--流模型（Flow Models）/21.png&quot; style=&quot;zoom: 25%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;    在上个Lecture中我们详细描述了自回归模型的原理，自回归的原理也可以用在流模型上，称之为&lt;strong&gt;自回归流模型&lt;/strong&gt;（&lt;strong&gt;Autoregressive Flow&lt;/strong&gt;）。既然是自回归的模型，那么就如上图，z1，z2依赖的值是不一样的。&lt;/p&gt;

&lt;p&gt;    看一些实验效果：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--流模型（Flow Models）/22.png&quot; style=&quot;zoom: 67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;    上图中右上角的图是x在二维空间的分布情况，注意一下，颜色只是一个分群的效果，不论紫色或者黄色都是x的样本。转换成z，且在二维空间中均匀分布，那么训练后得到z的分布情况则如右下角组图中左边的图所示。黄色和紫色的点没有区别，也都是样本，只是这样可以和x中的样本表达一个对应关系。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--流模型（Flow Models）/23.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;    这张也是一样理解，任意分布都可以转换为均匀分布。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1. n-D&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;    那么更高维呢？自回归流模型是否还能做到一样的事情。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--流模型（Flow Models）/24.png&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;    如果使用流模型，基于的是逆函数的原理来生成，那么x和z的维度需要一致，左边的图片有多少个值，z就也得有多少个值。（注意：这里的维度概念和我们通常理解的矩阵维度，空间维度是不一样的概念）。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Autoregressive Flows (AF)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;    如果是自回归流模型，先看看是怎么进行生成的：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--流模型（Flow Models）/25.jpeg&quot; style=&quot;zoom: 50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;    可以发现和自回归模型是一致的，先由由逆函数通过z1得到x1，再基于z2，x1得到x2，这样一直下去。而训练过程中的似然函数，和自回归模型中的也是一致的：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--流模型（Flow Models）/26.png&quot; style=&quot;zoom: 33%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--流模型（Flow Models）/27.png&quot; style=&quot;zoom: 67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--流模型（Flow Models）/28.png&quot; style=&quot;zoom: 33%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;其中绝对符内的是&lt;strong&gt;f &lt;/strong&gt;的&lt;strong&gt;雅可比矩阵（Jacobian determinant），&lt;/strong&gt;关于它的计算方式，可以参考[1]。&lt;strong&gt;f &lt;/strong&gt;必须是可微的，因此像一些不可微的激励函数比如ReLU，是不可以在这类模型中用的。另外，增加模型的深度可以直接将Flows接起来：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--流模型（Flow Models）/29.png&quot; style=&quot;zoom: 50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Inverse Autoregressive Flows&lt;/strong&gt;** (IAF)**&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--流模型（Flow Models）/30.png&quot; style=&quot;zoom: 67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;    新的算法IAF，和AF不一样的地方很容易发现，生成的时候，只依赖z了，所以可以一下子就根据z把图片生成出来，而不需要一个像素点一个像素点顺序生成了，但是训练的时候，却需要一个像素点一个像素点把完整的z计算出来。也就是说AF是训练可并行，生成得顺序，而IAF是训练得顺序，生成可并行。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Affine Flows&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--流模型（Flow Models）/31.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Affine Flows的参数就是一个可以把x-&amp;gt;z的矩阵和一个偏置向量。训练就是求这个矩阵和这个偏置向量的值。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Elementwise Flows&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--流模型（Flow Models）/32.png&quot; style=&quot;zoom: 50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--流模型（Flow Models）/33.png&quot; style=&quot;zoom: 50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这种方式可以大大减少计算量。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;NICE/RealNVP&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--流模型（Flow Models）/34.png&quot; style=&quot;zoom:50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;上面的公式很容易理解，就是把x分两半，前面一半直接给z，后面一半本质上是经过了一个Elementwise Affine Transformation。s和t都可以直接计算出来，s和t应该都是长度为d/2的向量。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--流模型（Flow Models）/35.jpeg&quot; style=&quot;zoom:50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;因此，计算量大大减少了。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--流模型（Flow Models）/36.png&quot; style=&quot;zoom:33%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--流模型（Flow Models）/37.png&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;上图是RealNVP的效果，可以发现还是不错的。&lt;/p&gt;

&lt;p&gt;那怎么把输入分两半呢：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--流模型（Flow Models）/38.png&quot; style=&quot;zoom:50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;如上图所示，可以不同位置分，但其实还可以不同通道分，可以不止分一种，可以分很多很多种，一起训练。另外就是RealNVP也会像其他神经网络一样，在一层一层网络推进的时候，减小每个通道的尺寸，增加通道的数量来更好地进行特征提取。如下图所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--流模型（Flow Models）/39.png&quot; style=&quot;zoom: 67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;输入是32&lt;em&gt;32&lt;/em&gt;c，通过第一层网络后，输出为两个16&lt;em&gt;16&lt;/em&gt;2c，通过第二层后输出为两个8&lt;em&gt;8&lt;/em&gt;4c，再通过第三层，最后输出为4&lt;em&gt;4&lt;/em&gt;16c。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--流模型（Flow Models）/40.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;由上图可以发现，把图片分两半的方式是很重要的，左边是通过checkerboard去分，右边则是上下左右分，可以发现，右边这样粗暴的分法带来的结果并不如左边精细的来得效果好。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Flow++ = MoL transformation + self-attention in NN&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--流模型（Flow Models）/41.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;bits/dim越低越好&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Glow （Invertible 1x1 convolutions + Large-scale training）&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--流模型（Flow Models）/42.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;    Glow是OpenAI的作品，可以生成十分真实的人脸。还是那句话，图像生成，不止GAN可以做到。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Continuous time flows (FFJORD)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;    允许不受限的架构，且保证了快速的概率计算。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;反量化&lt;/strong&gt;&lt;strong&gt;（Dequantization）&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;    如果把概率密度函数应用在离散数据的数据集上，会出现一些问题：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--流模型（Flow Models）/43.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;理论上来说，密度值可以无穷大，所以很容易出现上图中间的情况，出现和周边密度值完全脱离的特别大的密度值，这样也可以loss很小，但很明显是不合理的。解决办法之一是把概率密度函数转换成概率分布函数来做这件事情：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--流模型（Flow Models）/44.png&quot; style=&quot;zoom: 50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;但这样很麻烦，简单的是给数据集增加噪音，进行&lt;strong&gt;反量化&lt;/strong&gt;&lt;strong&gt;（Dequantization）&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--流模型（Flow Models）/45.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;老实说上面公式没看懂，感兴趣的可以找论文看，本质上就是把离散分布转换得连续一点：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--流模型（Flow Models）/46.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;还是之前的数据集，经过反量化转换后，就不容易在概率密度函数上产生很突兀的峰值了。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;结语：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;    流模型就到这里了，那么这类模型其实还有很多工作可以做，从上面的内容来看，关于她的工作还是比较少的，她还是有很大潜力可以变得更好，比如更快地生成更好的图片，更快地推理，更快地训练，更好地压缩图片等等。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;声明：文中所有图片和原理均来自课程和参考。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;参考：&lt;/p&gt;

&lt;p&gt;[1] Lil’Log, Flow-based Deep Generative Models, 2018&lt;/p&gt;
</description>
        <pubDate>Mon, 21 Mar 2022 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/UC-Berkeley%E9%9D%9E%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%B5%81%E6%A8%A1%E5%9E%8B-Flow-Models/</link>
        <guid isPermaLink="true">http://localhost:4000/UC-Berkeley%E9%9D%9E%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E6%B5%81%E6%A8%A1%E5%9E%8B-Flow-Models/</guid>
        
        <category>UC Berkeley CS294-158</category>
        
        
        <category>CV</category>
        
        <category>Unsupervised Learning</category>
        
        <category>Generative Model</category>
        
      </item>
    
      <item>
        <title>UC Berkeley非监督学习--自回归模型</title>
        <description>&lt;p&gt;    想系统学习一下生成网络，开个新坑，翻译整理一下UC Berkeley非监督学习的课程。这篇翻译第二讲&lt;strong&gt;Autoregressive Models&lt;/strong&gt;，&lt;strong&gt;自回归模型&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--自回归模型/1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;    这个课程总共十二讲，官方链接：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;https://sites.google.com/view/berkeley-cs294-158-sp20/home
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;    目前已整理过：&lt;/p&gt;

&lt;p&gt;        Lecture 1：&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg5ODIwMTUxNw==&amp;amp;mid=2247484985&amp;amp;idx=1&amp;amp;sn=87564039ce87c9618bbd7fd68cb83339&amp;amp;chksm=c06764fbf710eded7815eeeec344ab1b1807534664d18973ca9a3d566d8b7f1d37d62e2f2e8c&amp;amp;scene=21#wechat_redirect&quot;&gt;UC Berkeley非监督学习–介绍&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;        Lecture 7：&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg5ODIwMTUxNw==&amp;amp;mid=2247484457&amp;amp;idx=1&amp;amp;sn=745a486cd18e1f8b0e7e6c80c325a4ef&amp;amp;chksm=c06766ebf710effd996dc3ba4fa7c6cf8827fef00f09fce3d439c7e951c0e8b1ff987b8b0326&amp;amp;scene=21#wechat_redirect&quot;&gt;自监督学习（Self Supervised Learning）&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    这篇会讲一些非常简单的生成网络，比如histogram，还有最新的一些基于神经网络的自回归模型。&lt;/p&gt;

&lt;p&gt;    我们先考虑一个问题，一个长宽分别为128个像素的彩色图片，可以用多少维空间中的一个位置（点）来表达，答案是大概是五万维。模型的目标是可以得到复杂高维数据的分布。并实现计算上和统计上的高效性，计算上的高效性是计算可以快速完成，统计上的高效是指不需要太多数据，模型就可以得到正确的分布。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--自回归模型/2.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;    &lt;/p&gt;

&lt;p&gt;看具体的模型。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1. Histogram&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--自回归模型/3.png&quot; style=&quot;zoom: 80%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这里举个例子说这个算法可能会容易懂一点，假设你接了一个案子，预测华山山顶每天的最低气压，精确到个位数就行，然后你得到了最近三年每一天华山山顶上的最低气压，但只有一个气压值，对应的时间丢失了，然后你要用Histogram算法来预测明天华山山顶的最低气压值。有了这些数据，你可以得到每个气压值在过去三年中出现的次数，频率。也就得到了最低气压值的概率分布。在没有其他常识或者先验知识的情况下，你根据Histogram算法给出的答案，就是有最高概率的最低气压值。&lt;/p&gt;

&lt;p&gt;接下来看&lt;strong&gt;Inference&lt;/strong&gt;和&lt;strong&gt;Sampling&lt;/strong&gt;要怎么完成：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--自回归模型/4.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Inference&lt;/strong&gt;是推理出数据的概率，比如你有一个气压值，Inference就是推理这个气压作为最低气压值的概率。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Sampling&lt;/strong&gt;是抽样，抽样的方法是，首先计算总概率，一般是1，然后在0-1之间按均匀分布随机取一个数u，F&lt;strong&gt;i&lt;/strong&gt;计算的是P&lt;strong&gt;1&lt;/strong&gt;-P&lt;strong&gt;i&lt;/strong&gt;的总和，所以从P&lt;strong&gt;1&lt;/strong&gt;开始加上P&lt;strong&gt;2&lt;/strong&gt;，加上P&lt;strong&gt;3&lt;/strong&gt;，当加到P&lt;strong&gt;i&lt;/strong&gt;时，发现F&lt;strong&gt;i&lt;/strong&gt;恰好大于或者等于产生的随机数u，那么这个i就是要抽出的样本。&lt;/p&gt;

&lt;p&gt;一维空间的数据可以用这样的算法解决，那么多维空间的呢？&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--自回归模型/5.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;多维空间就不行，举个例子，比如我们有个数据集叫MNIST，里面都是二值图，即每个像素点的值都是0或1，那么可能的图有多少种呢？2的784次方个。所以如果你对这样一个数据集画直方图，横坐标有2的784次方个值，而这个数据集中的图片远没有这么多，因此就目前的现实情况，根本无法用Histogram的方式来计算概率分布。&lt;/p&gt;

&lt;p&gt;那么对于一维空间的数据，Histogram是个不错的算法吗？很明显也不是的。通常都会像下图中左边的样子，train set和test set，Histogram的结果虽然看着形状相似，但是有些值差别会特别大。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--自回归模型/6.png&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;因此，如果可以产生一个更平滑的分布结果，综合考虑每个值周边的概率分布来确定自己的概率分布的话，也许能更好地匹配测试集的概率分布。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--自回归模型/7.png&quot; style=&quot;zoom:50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2. Parameterized Distributions and Maximum Likelihood &lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;
&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;因此，与其去求变量的概率分布，不如去求概率分布函数。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;每个变量理论上都有一个概率分布函数，而通常这个函数是不容易被解出来的，我们可以做到的就是做很多很多假设，看看每个假设在现有数据集上的效果，然后用在现有数据集上表现最佳的那个假设来作为变量的概率分布函数。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--自回归模型/8.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;要完成上面的任务，需要解决两个问题，一是怎么做假设，另外一个问题是怎么怎么用现有的数据集评估假设。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--自回归模型/9.png&quot; style=&quot;zoom: 67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;假设的话，可以根据一些经验设定，比如解决图像识别问题，可以用卷积神经网络。而假设的评估，则需要损失函数。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--自回归模型/10.png&quot; style=&quot;zoom: 80%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;一般用来设计损失函数，有极大似然估计和KL散度（参考：&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg5ODIwMTUxNw==&amp;amp;mid=2247484059&amp;amp;idx=1&amp;amp;sn=422a4565edeba1b9087615ed0f72a59a&amp;amp;chksm=c0676059f710e94fe65e01143f15585b9ef1e7f46187f30a40fc5b9d6dd9c5bc38bddb2cf115&amp;amp;scene=21#wechat_redirect&quot;&gt;Cross Entropy Loss&lt;/a&gt;）。这里用&lt;strong&gt;极大似然估计&lt;/strong&gt;说明，我们的目的是求概率分布函数，比如一个图像识别问题，其中一个假设是一个三层的卷积网络可以做这个任务，但构成这个网络需要一堆参数，这些参数一开始是未知的，所以问题就变成了，如何求这些参数，使得这个函数可以更好地用作现有数据的概率分布函数。那这个待求参数的网络，假设（其实带不同参数的网络也可以被看成不同的假设），函数，我们也可以称为似然函数。那如何评估不同参数下的函数，方法其实很简单，就是最大化现有样本的出现的概率（既然这个样本曾经出现过，那么我们认为，它有很高的概率再次出现，如果这个样本曾经多次出现，那么它应该会有更高的概率会再次出现）。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--自回归模型/11.png&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;完成极大似然估计或者KL散度，可以用SGD算法。&lt;/p&gt;

&lt;p&gt;除了极大似然估计，在设计损失函数的时候，用贝叶斯加入先验函数也是常使用的方法。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3. Autoregressive Model&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;极大似然估计是频率派，也就是说是完全基于现有数据来评估模型，而贝叶斯属于贝叶斯派，会加入一些先验知识。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--自回归模型/12.png&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;举个例子，比如事件A是世界即将毁灭，假设P(A) = 0.000001，事件B是太阳从西边升起，假设P(B) = 0.0000001，假设如果世界即将毁灭，太阳会从西边升起的概率是0.001，即P(B|A) = 0.001，那么当我们看到太阳从西边升起时，我们可以计算出世界即将毁灭的概率P(A|B) = P(B|A)P(A)/P(B) = 0.01，这个公式我们称之为贝叶斯公式。也就是说一件事情发生的概率，会因为一些已经发生的事情而产生改变，当我们判断一件事情发生的概率的时候，需要综合考虑相关的事件。而&lt;strong&gt;自回归模型&lt;/strong&gt;则正是基于这种理念。&lt;/p&gt;

&lt;p&gt;来看一个只有两个值的自回归模型：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--自回归模型/13.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;那这种自回归模型有什么问题呢？&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--自回归模型/14.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;首先，对于高维空间数据，依然不友好，另外作为条件的数据都是同等对待的，但他们其实和要预测的事件也有亲疏远近之分，而在之前的自回归模型中没有体现出来。解决方案有两个，一个是用Reccurent Neuarl Network，一个是Masking。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;4. Recurrent Neural Nets （RNN）&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--自回归模型/15.png&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这是上一篇中提到的，在NLP领域十分有效的&lt;strong&gt;CHAR-RNN&lt;/strong&gt;，图右边是一个非常典型的RNN网络。这是一个自回归模型。本质是根据之前出现的字母来推测下一个字母。&lt;/p&gt;

&lt;p&gt;RNN在图片生成上的应用，如果单纯根据之前的像素点（像素点依序排列）来推测下一个像素点，可以做到如下效果：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--自回归模型/16.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;但图像和文字有所不同，文字是一维的，黑白图像是二维的，所以如果依序输入像素点的时候能同时输入每个像素点在图片中的位置，那么训练效果会好很多（很多最先用在NLP领域的模型在被尝试用在CV领域时，都会加入position encoding，典型如VIT）：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--自回归模型/17.png&quot; style=&quot;zoom:100%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;5. Masking-based Models&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;（1）Masked Autoencoder for Distribution Estimation (MADE)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--自回归模型/18.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;MADE的运作方式就是在一般的aotoencoder上加mask，左边是一个很普通的全连接网络，最后预测出来的每个值和输入的每个值都是相关的，模型会去根据输入样本的所有数据来产生输出，但每层网络加上mask之后，就不一样了，mask不是随机产生的，而是根据需求设计过的，如右边添加了mask后的模型。MADE做自回归模型要输出的和RNN做自回归模型要输出是一致的，都是为了完成下面的计算：&lt;/p&gt;

&lt;p&gt;                &lt;img src=&quot;../assets/images/UC Berkeley非监督学习--自回归模型/19.jpeg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;为了实现这样的目标，那么MADE网络最后输出的值，比如上图中网络最后一层的1的输出，它不依赖于任何输入的值，因此它表示一个完全独立的概率分布p(x&lt;strong&gt;2&lt;/strong&gt;)，而2的输出是依赖于x&lt;strong&gt;2&lt;/strong&gt;这个输入的，3的输出则同时依赖于x&lt;strong&gt;2&lt;/strong&gt;，x&lt;strong&gt;3&lt;/strong&gt;的输入，因此可以用来表达条件概率分布。这样MADE就可以获得要用来做自回归的所有概率分布。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--自回归模型/20.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这是MADE用于数字生成的效果图，训练集是MNIST。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--自回归模型/21.png&quot; style=&quot;zoom: 67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;MADE和其他方法的比较。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--自回归模型/22.png&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;我们希望MADE具有图像生成的能力，即可以通过训练，学习到特征，从而生成符合预期但却没有过的东西（模型没有见过），而不是直接把看过的图片复制出来，因此研究者会比较生成的图片和训练集中和这些图片最接近的图片。如果完全一致，模型其实只是记忆和复刻了训练集，而如果是特征一致，但细节不一致，就说明有生成的能力。上图左边是模型生成的图片，右边是和生成的图片最接近的训练集中的图片，发现大多数其实是特征一致，但是细节不一致，所以我们可以初步得到结论，MADE具有生成的能力。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--自回归模型/23.png&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;自回归模型图片中数据输入是有一个顺序的，那么怎么给一个图片中的数据排个序，怎么排序才能使模型有更好的生成能力，这也是一个问题。上图中尝试了不同的像素排序方式，比如完全随机，比如先单数后双数，比如一行一行扫描，一列一列扫描等，效果大家自己观察了，PPT上的这个图和视频课程里的这个图出入有点大。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--自回归模型/24.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Mask的数量和训练效果的关系，如上。不过值得注意的是，因为训练的是生成网络，所以模型的优劣有时候不太能直接用这种硬指标来衡量。&lt;/p&gt;

&lt;p&gt;视频课程也有描述怎么用训练好的模型sample，这里基于一开始的那张图简单说一下，&lt;strong&gt;x1&lt;/strong&gt;可空，然后产生&lt;strong&gt;p(x2)&lt;/strong&gt;，根据&lt;strong&gt;p(x2)&lt;/strong&gt;确定&lt;strong&gt;x2&lt;/strong&gt;的值，作为输入，输出&lt;strong&gt;p(x3|x2)&lt;/strong&gt;，根据&lt;strong&gt;p(x3|x2)&lt;/strong&gt;确定&lt;strong&gt;x3&lt;/strong&gt;的值，再输入&lt;strong&gt;x3&lt;/strong&gt;，再跑模型得到&lt;strong&gt;p(x1|x2,x3)&lt;/strong&gt;，以此确定&lt;strong&gt;x1&lt;/strong&gt;的值。可以发现，这个模型在sample的时候其实很像RNN，比如上面生成数字图的任务，要一个一个像素生成，要生成一张（28，28）大小的二值图，需要把这个模型跑784次。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;（2）Wavenet [Masked Temporal (1D) Convolution]&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--自回归模型/25.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;上图就是一个简单的Wavenet网络，每一层都有一个一维的长度为2的卷积核，步长为1。这个方法的优点是容易实现，不论输入有多长，参数量没有变化。缺点是计算出的概率分布，能观察到的输入是固定的，比如上图中，虽然输出是p(xi+1|x&amp;lt;=i)，但实际上计算的分布是p(xi+1|x（i-4) - i)，如果想要p(xi+1|x&amp;lt;=i)，那么还是需要调整输入的大小，或者重新训练匹配输入大小的网络。当然也可以有其他解决方式，比如下面这个网络，用了Dilated Conv。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--自回归模型/26.jpeg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--自回归模型/27.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这是Wavenet的生成效果。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--自回归模型/28.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这是加入position encoding之后，Wavenet的生成效果。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;（3）PixelCNN [Masked Spatial (2D) Convolution]&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--自回归模型/29.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;上面的方法都是一维的方式加上position encoding来完成图像生成，那么当然就有人会尝试二维卷积的方式来做这件事情。PixelCNN是2016年的时候被提出来的一个网络结构，这个网络依然是一个像素点一个像素点依序生成，如上图所示，现在想要生成右图中红色那个位置的像素值，如果用一个3*3的卷积核，那么会被参考的像素值是它周边的四个已经生成的像素值（蓝色位置），其他五个不参考是因为他们还没有被生成出来。这是一层，一般会有多层。这里先看一个Sample的效果，是一个一个像素点生成的：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--自回归模型/30.png&quot; style=&quot;zoom:33%;&quot; /&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--自回归模型/31.png&quot; style=&quot;zoom:33%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--自回归模型/32.png&quot; style=&quot;zoom:33%;&quot; /&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--自回归模型/33.png&quot; style=&quot;zoom:33%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--自回归模型/34.png&quot; style=&quot;zoom: 67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;如上图所示，已经生成的图片如左图所示，左边是输入，而输出是一个概率分布，如果像素值的区间是[0,255]，那么就是该点像素值在0到255区间的概率分布，如果是二值图，那么横坐标只有两个值，0和1，输出就是像素值在[0,1]区间的概率分布。像素值是离散值。如果是彩色图，输出应该是三个概率分布。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;（3）Gated PixelCNN&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;如果PixelCNN网络有不同层数，那么会被参考的像素值如下图[1]所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--自回归模型/35.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;按现在的结构，网络层数越多，生成这个像素值会参考到的范围越大，但是会发现，因为卷积核本身的结构特质，会有同样也很近的像素值，没有被平等地参考。应该但是没有被参考的部分被称之为Blind spot。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--自回归模型/36.png&quot; style=&quot;zoom:50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;为了解决这个问题，Gated PixelCNN被提了出来（图来自参考[1]）：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--自回归模型/37.png&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;为了规避Blind Spot，这里设计了两个卷积核，一个是上图中绿色部分，中心点是m，m是要生成的r的正上方的位置。卷积核是3&lt;em&gt;3大小，但是最后一行是0，这样不管网络有多少层，右边都不会再出现Blind Spot。但这样会忽略掉左边的已经生成的像素值，因此还有一个卷积核是1&lt;/em&gt;3，只是右边两个值是0。不同层数的Gated PixelCNN参考的像素值范围如下图[1]所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--自回归模型/38.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这样就没有Blind Spot了。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--自回归模型/39.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--自回归模型/40.png&quot; style=&quot;zoom: 50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Gated PixelCNN网络架构如上图所示。之所以这个网络前面加了Gated字眼，不是因为卷积核的变化，而是网络结构中加入了类似LSTM中记忆门（forget gate）的机制，上图中tanh函数生成的是概率分布值，而σ生成的是遗忘值，决定tanh生成的概率分布该如何保留。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--自回归模型/41.png&quot; style=&quot;zoom:50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;上图是一些方法的比较。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;（4）PixelCNN++&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;PixelCNN或者Gated PixelCNN&lt;/strong&gt;每次输出的是一个分布，如果是彩色图，输出的是三个在[0, 255]区间上的概率分布。这存在的问题是，首先，输出的量大，计算量也就大，另外一个问题是这个像素是254的概率和这个像素是255的概率其实是强相关的，但这种方法有点像在解两个问题。因此PixelCNN++做了改变。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--自回归模型/42.png&quot; style=&quot;zoom: 80%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;本质上是把一个求离散概率分布的问题变成了求连续概率分布的问题，如上面两个公式，最后得到的不是一个概率分布，而是一个概率分布函数，u决定了这个函数的位置，s决定了这个分布的形状，如下图所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--自回归模型/43.png&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;PixelCNN++还在通道上做了改进，PixelCNN或者Gated PixelCNN是分别输出三个概率分布，但颜色之间也是有相关性的，PixelCNN++则同时参考了不同颜色，输出的也是联合概率分布。&lt;/p&gt;

&lt;p&gt;PixelCNN或者Gated  PixelCNN无法依赖远距信息，因此PixelCNN++为每一层添加了一个下采样，这样虽然损失了信息，但是扩大了生成像素可以参考的范围，而损失的信息可以用额外的方式来补偿，如下图所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--自回归模型/44.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;模型的测试结果如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--自回归模型/45.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;更详细可以参考[2]或者看原paper。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;（5）PixelSNAIL&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;还有融入了残差模块和注意力机制的PixelSNAIL，这部分课程讲的不太清楚，但提出这个网络的有公布论文和代码。这里就简单描述一下这个网络，主要是融入了attention机制：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--自回归模型/46.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--自回归模型/47.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;卷积让网络只能参考到一部分信息，但是attention可以参考所有信息。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--自回归模型/48.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;进一步说，应该是masked-attention。这种机制让这个模型相较于其他模型，在生成一个像素值的时候，几乎可以参考之前已经生成的所有像素值。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--自回归模型/49.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这种方法可以允许模型用不同的顺序生成图片，比如上面这种顺序。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--自回归模型/50.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;网络的核心就是一个Residual Block和一个Attention Block。&lt;/p&gt;

&lt;p&gt;他的效果超越了之前的模型：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--自回归模型/51.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--自回归模型/52.png&quot; style=&quot;zoom:50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;（5）其他&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Class-Conditional PixelCNN 可以指定数字生成。&lt;/li&gt;
  &lt;li&gt;Hierarchical Autoregressive Models with Auxiliary Decoders可以生成真实到肉眼无法分辨的图片。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--自回归模型/53.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;PixelCNN可以用来提高图片清晰度&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--自回归模型/54.png&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--自回归模型/55.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;4. PixelCNN可以用来黑白转彩&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--自回归模型/56.png&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--自回归模型/57.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;PixelCNN一个一个像素点生成有点慢？可以加速&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--自回归模型/58.png&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;分块加速，比如把图片分成四块，如上图所示的方法加速。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--自回归模型/59.png&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;也可以尝试其他技术加速，比如cache activations。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--自回归模型/60.png&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--自回归模型/61.png&quot; style=&quot;zoom:50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;以上是加速效果。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;也可以做视频生成&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--自回归模型/62.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;也可以做人脸生成&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--自回归模型/63.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;PixelCNN因为是一个像素一个像素输入，一个概率分布一个概率分布输出，所以我们很难得到一个特征向量来代表一个人脸。然后通过改变特征向量来生成不同的人脸。加入了Fisher Score，自回归模型也能很好的做一张脸到另一张脸的转换，如上图所示，左边做人脸的变化，出来的效果像是把两张人脸叠起来，先让一张脸显现，弱化另外一张脸，再逐渐让另外一张脸显现，但右边的图不一样，从一张脸到另外一张脸的变化中，产生的都是真实度高的不同的人脸。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--自回归模型/64.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;下面一行用了Fisher Score的方法，可以发现，比起上面那行，下面这行在慢慢变化的过程中，产生的都是真实度高的人脸。&lt;/p&gt;

&lt;p&gt;声明：以上所有图片和技术内容，均来自UC Berkeley非监督学习课程和参考文章，没有原创理论和图片。&lt;/p&gt;

&lt;p&gt;参考：&lt;/p&gt;

&lt;p&gt;[1] Jessica Dafflon,  PixelCNN’s Blind Spot, towards data science, 2019&lt;/p&gt;

&lt;p&gt;[2] Harshit Sharma, Auto-Regressive Generative Models (PixelRNN, PixelCNN++), 2017&lt;/p&gt;
</description>
        <pubDate>Wed, 09 Mar 2022 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/UC-Berkeley%E9%9D%9E%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E8%87%AA%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B/</link>
        <guid isPermaLink="true">http://localhost:4000/UC-Berkeley%E9%9D%9E%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E8%87%AA%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B/</guid>
        
        <category>UC Berkeley CS294-158</category>
        
        
        <category>CV</category>
        
        <category>Unsupervised Learning</category>
        
        <category>Generative Model</category>
        
      </item>
    
      <item>
        <title>UC Berkeley非监督学习--介绍</title>
        <description>&lt;p&gt;    想系统学习一下生成网络，开个新坑，翻译整理一下UC Berkeley非监督学习的课程。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--介绍/1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;    这个课程总共十二讲，官方链接：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;https://sites.google.com/view/berkeley-cs294-158-sp20/home
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;    之前为了搞明白自监督学习的概念，整理过Lecture 7：&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg5ODIwMTUxNw==&amp;amp;mid=2247484457&amp;amp;idx=1&amp;amp;sn=745a486cd18e1f8b0e7e6c80c325a4ef&amp;amp;chksm=c06766ebf710effd996dc3ba4fa7c6cf8827fef00f09fce3d439c7e951c0e8b1ff987b8b0326&amp;amp;scene=21#wechat_redirect&quot;&gt;自监督学习（Self Supervised Learning）&lt;/a&gt;，这次没有意外的话至少会整理Lecture 1-6。&lt;/p&gt;

&lt;p&gt;    这篇整理这个课程的Lecture 1：Introduction。课程的介绍。&lt;/p&gt;

&lt;p&gt;    那什么是&lt;strong&gt;非监督学习&lt;/strong&gt;(&lt;strong&gt;Unsupervised Learning&lt;/strong&gt;):&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--介绍/2.png&quot; style=&quot;zoom: 67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;    非监督学习，用没有标签的数据训练深度神经网络，学习特征，主要分两类，一类是生成网络，像GAN，VAE这些，一类是自监督学习，label是机器自己产生的，不是人工标注的。&lt;/p&gt;

&lt;p&gt;    那么为什么要用非监督学习呢？&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--介绍/3.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;    说到底，还是因为监督学习，效率太低。上图是Hinton的思考，Hinton也有一门神经网络课程，他喜欢通过对人脑运行机制的思考来探索人工智能的解决方案，会通过理解人脑的运行机制和特质来思考智能的来源，人大概活10^9秒，但是我们有大约10^14个神经触突。那么特别明显，如果我们是通过与世界的互动来获得标签，训练大脑，那么我们应该来不及聪明就死去了。所以人类获得智能的主要方式可能不是监督学习，而是非监督学习。&lt;/p&gt;

&lt;p&gt;    这里插一些题外话，关于Hinton，Hinton最初关于神经网络的灵感来源于高中时候获知的一些生物学上对大脑的研究结果，感兴趣的可以找Hinton的课程或者演讲看一看，比起枯燥的算法，这些算法的灵感来源，科学家们的思维方式，如何觉察，如何获得的灵感和毕生的执着和方向。这些可能是更值得学习的“算法”。   &lt;/p&gt;

&lt;p&gt;另外一位科学家也有相同的想法：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--介绍/4.png&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;    如果把深度学习领域比喻成一块蛋糕，那么LeCun认为，强化学习只是蛋糕上的樱桃，监督学习是蛋糕里的冰，而非监督学习才是蛋糕本身。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--介绍/5.png&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;    也有人从不同的角度来思考这个问题，比如思考理想化的智能是什么，就是压缩，即输入信息后，要能够提取所有特征，提取特征即产生一个简短的表达或描述，那么这个过程本质上就是对信息的压缩。根据奥卡姆剃刀原理，使用越少假设的理论越有可能是对的，延伸到深度学习，Solomonoff 的归纳推理理论是一个数学证明，即如果一个宇宙是由算法生成的，对该宇宙的观察，编码为一个数据集，最好由该数据集的最小可执行档案来预测，通俗来说就是程序越短，越有可能是适用的。AIXI是一个通用人工智能的数学理论形式，结合了Solomonoff Induction和顺序决策理论，是一个强化学习代理，最大化从环境中获得的期望总回报。AIXI同时考虑了所有可计算的假设（或环境），每一步，会用每个程序计算下一步动作和评估奖励，承诺奖励会根据该程序构成真实环境的主观信念进行加权。这种信念是根据程序的长度计算得出的，根据Solomonoff Induction，越长的程序越不可能是构成真实环境的程序。AIXI会在所有这些程序的加权和中选择具有最高期望总奖励的动作来执行。&lt;/p&gt;

&lt;p&gt;    这几个概念感兴趣的可以自己再梳理下，课程里只是一语带过了，没有仔细讲。&lt;/p&gt;

&lt;p&gt;    撇开理论上的，我们来看一看非监督学习的一些应用：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--介绍/6.png&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;首先非监督学习可以产生新的数据，也可以根据一些输入来合成数据，比如输入一句话，产生一幅图，非监督学习可以用于信息压缩，训练得越好的模型压缩效果越好，压缩得到的特征向量可以用于下游任务的模型开发和训练，下游任务如果是监督学习，通常可以大大减少需要的人工标注量。另外，非监督学习中成功的模型架构也可以用于监督学习或者强化学习，或者给开发者以启发。 &lt;/p&gt;

&lt;p&gt;    这里列一些非监督学习目前的成果（这些可以去看视频课程，因为没有什么难懂的点，另外有些示例是视频，这里没有上传）：&lt;/p&gt;

&lt;p&gt;    &lt;strong&gt;1. 图像生成：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--介绍/7.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;最早，可能是Hinton他们尝试用神经网络生成手写的数字。这个是2006年的事情了。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--介绍/8.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;接下来VAE在2013年被提出来了，可以发现VAE产生的图片是模糊的，但是VAE比之后出来的GAN有自己的优点，这个之后说。   &lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--介绍/9.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;紧接着，2014年，GAN被发表，开始尝试生成人脸和风景，一开始效果并不好，但结果已经足够让人震撼。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--介绍/10.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;GAN开始产生各式各样的变种，尝试去完成各种各样的任务，比如生成室内图。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--介绍/11.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;更好的人脸生成，但很多生成的不是很好。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--介绍/12.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;由低解析度的图片产生高解析度的图片，把模糊图片变清晰。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--介绍/13.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;改造，把马变成斑马。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--介绍/14.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;改变特征向量，产生不同的图。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--介绍/15.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;清晰，高真人脸。&lt;/p&gt;

&lt;p&gt;    &lt;strong&gt;2. 语音生成&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--介绍/16.png&quot; style=&quot;zoom: 50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;    模型产生的语音和真实的人的语音是很难被区别开的。&lt;/p&gt;

&lt;p&gt;    &lt;strong&gt;3. 视频生成&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--介绍/17.png&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;    &lt;strong&gt;4. 文本生成&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--介绍/18.png&quot; style=&quot;zoom: 50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Char-rnn是个非常优秀的文本生成模型，他不挑内容，公式也能生成，代码也能生成，英语可以，其他语言也可以，网络结构是基于LSTM，也非常简单。但这个模型现在被用得比较少了。现在大家的注意力都在Transformer上。基于Transformer，OpenAI开发了GPT-2，机器人可以产生有意义的文字，甚至可以说故事。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--介绍/19.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;https://app.inferkit.com/demo
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;有空可以去上面的网址逗逗机器人。&lt;/p&gt;

&lt;p&gt;    &lt;strong&gt;5. 压缩&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--介绍/20.png&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;以上是无损压缩，压缩按是否有信息损失可以分为无损压缩和有损压缩，无损压缩时，没有信息会在压缩过程中损失，所以比较的是各个方法可以把文件压缩到多小，有损压缩在信息压缩的过程中会造成信息损失，但通常可以把文件压很小，但也因此信息质量会变差，因此会比较压缩到同样大小文件时，不同压缩方法压缩出来的文件品质如何，比较的是压缩后的信息质量。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--介绍/21.png&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这是有损压缩。有损压缩更受欢迎。&lt;/p&gt;

&lt;p&gt;    &lt;strong&gt;6. 下游任务 – 情感计算&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--介绍/22.png&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;比如上面这段话，不同的句子有不同的感情色彩，前几句，情感是正面的，后面几句情感则是负面的。下游任务是说，这个功能是用训练好的语义模型进行再训练或者从训练好的模型中挖掘有用信息等方式来完成的。&lt;/p&gt;

&lt;p&gt;    &lt;strong&gt;7. 下游任务 – 语义理解&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--介绍/23.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;注意一下，9是Human Level，但这不是说现在机器的语义理解就已经强过人类了，只是在特定的数据集上或任务上如此表现。&lt;/p&gt;

&lt;p&gt;​	&lt;strong&gt;8. 下游任务 – 图像识别&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--介绍/24.png&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;继语义之后，非监督学习在图像领域也获得了巨大成功。这个可以看&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg5ODIwMTUxNw==&amp;amp;mid=2247484457&amp;amp;idx=1&amp;amp;sn=745a486cd18e1f8b0e7e6c80c325a4ef&amp;amp;chksm=c06766ebf710effd996dc3ba4fa7c6cf8827fef00f09fce3d439c7e951c0e8b1ff987b8b0326&amp;amp;scene=21#wechat_redirect&quot;&gt;自监督学习（Self Supervised Learning）&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;最后老师总结了一下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/UC Berkeley非监督学习--介绍/25.png&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;[1] Alex_Altair, An Intuitive Explanation of Solomonoff Induction, LessWrong, 2012&lt;/p&gt;
</description>
        <pubDate>Tue, 01 Mar 2022 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/UC-Berkeley%E9%9D%9E%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E4%BB%8B%E7%BB%8D/</link>
        <guid isPermaLink="true">http://localhost:4000/UC-Berkeley%E9%9D%9E%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E4%BB%8B%E7%BB%8D/</guid>
        
        <category>UC Berkeley CS294-158</category>
        
        
        <category>Unsupervised Learning</category>
        
      </item>
    
      <item>
        <title>以图片为目标的视觉强化学习 -- 代码解析上篇(rlkit安装及部分代码及函数的解析和使用)</title>
        <description>&lt;p&gt;    之前有讲过一篇论文，今天来讲讲它的代码：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/以图片为目标的视觉强化学习 -- 代码解析上篇(rlkit安装及部分代码及函数的解析和使用)/1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;论文解析的链接是：&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg5ODIwMTUxNw==&amp;amp;mid=2247484273&amp;amp;idx=1&amp;amp;sn=8bd92202039862f48875a58bdaee4999&amp;amp;chksm=c06761b3f710e8a53bb9cf7b8fa580fe250de2ddab6ca5db042206fb0241a8b2a954c4e3e862&amp;amp;scene=21#wechat_redirect&quot;&gt;以图片为目标的视觉强化学习&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/以图片为目标的视觉强化学习 -- 代码解析上篇(rlkit安装及部分代码及函数的解析和使用)/2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;    这篇研究以及这篇研究的后续研究，源代码都有公开，我们的目标是把这个库都解析一遍，感兴趣的话，关注吧。下面是相关源代码的链接：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;https://github.com/rail-berkeley/rlkit
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;现在要说的这个工作我们称呼它RIG，RIG适用的rlkit版本和最新的两个工作适用的rlkit版本不一样，我们先看RIG适用的rlkit。&lt;/p&gt;

&lt;p&gt;    论文开发者直接开发了一个工具，里面有众多强化学习的算法，方便做相关研究的渣渣们，比如我，直接拿来用，但前提你得看得懂&lt;img src=&quot;../assets/images/以图片为目标的视觉强化学习 -- 代码解析上篇(rlkit安装及部分代码及函数的解析和使用)/3.png&quot; style=&quot;zoom:50%;&quot; /&gt;。那么看懂就交给我了。&lt;/p&gt;

&lt;p&gt;    我们先来安装和解析一下这个工具，首先看安装指引：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cp rlkit/launchers/config_template.py rlkit/launchers/config.py
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;    然后我们看看config.py里面都做了些什么：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;os&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;os.path&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;rlkit&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# 设定项目目录
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;rlkit_project_dir&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dirname&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rlkit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__file__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pardir&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;LOCAL_LOG_DIR&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rlkit_project_dir&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'data'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


&lt;span class=&quot;c1&quot;&gt;# 接下来设定大部分与远程服务器相关
&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 代码目录，可能不止一个，不止一个就添加在后面
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CODE_DIRS_TO_MOUNT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;rlkit_project_dir&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# '/home/user/python/module/one', Add more paths as needed
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# 工作需要用到mujoco模拟器，如果你mujoco安装的位置特殊，这里可能要改
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DIR_AND_MOUNT_POINT_MAPPINGS&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
    &lt;span class=&quot;nb&quot;&gt;dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;local_dir&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getenv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'HOME'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'.mujoco/'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;mount_point&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'/root/.mujoco'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# 跑程序的代码地址
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;RUN_DOODAD_EXPERIMENT_SCRIPT_PATH&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rlkit_project_dir&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'scripts'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'run_experiment_from_doodad.py'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# '/home/user/path/to/rlkit/scripts/run_experiment_from_doodad.py'
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


&lt;span class=&quot;c1&quot;&gt;# 接下来是AWS，SLURM，和GCP的一些设定，
# 我目前都没用到，暂时不提，用到的小伙伴可以看一下
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;关于config.py文件，不用doodad的话，要把下面两行改一下，不然之后跑程序会报错：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# If not set, default will be chosen by doodad
#AWS_S3_PATH = 's3://bucket/directory
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;改为（其实就是把注释去掉，再补个冒号），我的环境里它不会被用到，只是调试起来方便一些：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# If not set, default will be chosen by doodad
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AWS_S3_PATH&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'s3://bucket/directory'&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;接下来创建一个虚拟代码环境，他提供了三个虚拟环境配置文件：linux-cpu-env.yml，linux-gpu-env.yml，mac-env.yml。一般是linux-gpu：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;conda&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;env&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;create&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;environment&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linux&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gpu&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;env&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;yml&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;在跑之前我们看里面写了点啥，name是虚拟环境的名称，channels是虚拟环境安装软件的源，下面的dependencies是虚拟环境依赖的软件，这里就不列全了：   &lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rlkit&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;channels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kne&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# for pybox2d
&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pytorch&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;anaconda&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# for mkl
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dependencies&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cython&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ipython&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# technically unnecessary
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;我自己不习惯用别人写好的脚本建立环境，喜欢一边看代码一边解决依赖问题。&lt;/p&gt;

&lt;p&gt;首先我们要解决最重要的一个依赖，MuJoCo，强化学习的环境模拟常用的软件，以前是个付费软件，现在免费了，可能是有大佬买了，现在似乎属于DeepMind，DeepMind属于Google：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;https://mujoco.org/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;代码里用的MuJoCo版本是1.5，我喜欢用最新的，我们试试2.1，不行再回来换1.5，MuJoCo安装起来还是挺费劲的，遇到问题耐心些，多搜一搜：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;mkdir&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;~/&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mujoco&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;cd&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;~/&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mujoco&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# 到mujoco官网-&amp;gt;download页面-&amp;gt;选2.1.0版本-&amp;gt;下载linux版
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;wget&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;https&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;//&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;github&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;com&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;deepmind&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mujoco&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;releases&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;download&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;2.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mujoco210&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linux&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x86_64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gz&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;tar&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xvf&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mujoco210&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linux&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x86_64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gz&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'export LD_LIBRARY_PATH=$HOME/.mujoco/mujoco210/bin:$LD_LIBRARY_PATH'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;~/&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bashrc&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;source&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;~/&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bashrc&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# 以上mujoco就下载安置好了
# 接下来安装mujoco-py
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;git&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;clone&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;https&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;//&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;github&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;com&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;openai&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mujoco&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;py&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;git&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;cd&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mujoco&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;py&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;pip3&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;install&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;requirements&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;txt&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;pip3&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;requirements&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;txt&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;python3&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;setup&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;py&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;install&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;#----------------------------------------
# 接下来是一些你可能import mujoco_py失败，甚至上面就没装成功，而需要进行的步骤
# 按错误提示选择性执行
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sudo&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;apt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gcc&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sudo&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;apt&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;install&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;libosmesa6&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dev&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sudo&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;apt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;python3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;devel&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sudo&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;apt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sudo&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;apt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;patchelf&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sudo&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;apt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;install&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;libglew&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dev&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/lib/nvidia'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;~/&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bashrc&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;echo&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$HOME/.local/bin'&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;~/&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bashrc&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'export LD_PRELOAD=/usr/lib/x86_64-linux-gnu/libGLEW.so'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;~/&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bashrc&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;source&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;~/&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bashrc&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;如果可以import mujoco_py执行成功，且可以跑一些示例代码，就表示安装成功了。&lt;/p&gt;

&lt;p&gt;    再回过头看rlkit，他除了提供虚拟环境的方案，还提供了Docker文件，Docker我不喜欢用，当然，主要是因为没下功夫，用不好，所以只能不喜欢，对这些比较擅长的可以试着用Docker。&lt;/p&gt;

&lt;p&gt;    rlkit调用GPU的方式：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;rlkit.torch.pytorch_util&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ptu&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ptu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_gpu_mode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;     如果用doodad来执行方法，则直接用下面的方式调用gpu，然而我测试发现，不用doodad，下面这种方式也可以成功调用gpu：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;run_experiment&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(...,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;use_gpu&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;    他们会建议用doodad来执行python程序，这里我们更想偏向于原理性代码的讨论，doodad部分的代码就不涉及了。&lt;/p&gt;

&lt;p&gt;    接下来我们看RIG的代码，在examples/rig/目录下，有两个目录，四个文件，我们一个一个开始，首先看examples/rig/pointmass/rig.py：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;multiworld.envs.pygame.point2d&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Point2DWallEnv&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;rlkit.launchers.launcher_util&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;run_experiment&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;rlkit.launchers.rig_experiments&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grill_her_td3_full_experiment&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;要安装一下multiworld，这个工具也是该团队开发的：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;git&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;clone&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;https&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;//&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;github&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;com&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vitchyr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;multiworld&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;git&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;cd&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;multiworld&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;python&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setup&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;py&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;install&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;pip&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gym&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;pip&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pygame&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;pip&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;boto3&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;pip&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gtimer&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;pip&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sk&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;video&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;pip&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gitpython&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;关于安装rlkit，rlkit依赖版本较低的python和tensorflow，再加上跑不同程序要用到的rlkit版本还不太一样，我们反正要解析源代码，这里就不安装rlkit了，直接把rlkit的源码包放在主程序的目录下。如果想安装rlkit，可以按照他们给的方法操作，之后直接pip install rlkit就行。亲测不安装是可以的。&lt;/p&gt;

&lt;p&gt;    接着看main函数，先定义了一个字典，里面都是参数，字典里还嵌套字典，层层叠叠，难怪AI工程师会被调侃调参大师，这里暂时不一一看，之后用到了会提：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    &lt;span class=&quot;n&quot;&gt;variant&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;imsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;84&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.......&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;algorithm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'RIG'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;    配置完参数之后，就是跑训练代码了：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    &lt;span class=&quot;n&quot;&gt;run_experiment&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grill_her_td3_full_experiment&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#rig算法实验的函数，以variant为参数
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exp_prefix&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'rlkit-pointmass-rig-example'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#实验名称
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# 实验方式：默认是local，我们这里没装doodad。
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# 单机用here_no_doodad可以跑，也可以调用GPU
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# 其他方式暂时不研究了，有兴趣的可以研究
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# “local”，
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# “docker_local”，
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# “ec2”，
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# 'here_no_doodad'， 
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;mode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'here_no_doodad'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
&lt;span class=&quot;err&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;variant&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;variant&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# 参数
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;use_gpu&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# 要用GPU跑就打开
&lt;/span&gt;    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;    在这样的配置下，我们看代码是怎么跑的（会略过不太重要的代码），下面是run_experiment里比较重要的代码：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    &lt;span class=&quot;n&quot;&gt;run_experiment_kwargs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# 实验名称，默认会带上时间
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;exp_prefix&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exp_prefix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# 参数
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;variant&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;variant&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# 实验ID
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;exp_id&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exp_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# 随机种子，不设定就随机产生
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;use_gpu&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;use_gpu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# 默认是‘last’,作用之后说
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;snapshot_mode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;snapshot_mode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# 默认是1，作用之后说
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;snapshot_gap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;snapshot_gap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# 没装git就是None,暂时就None吧
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;git_infos&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;git_infos&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#这里应该是rig.py 
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;script_name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__file__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mode&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'here_no_doodad'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;run_experiment_kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'base_log_dir'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;base_log_dir&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;run_experiment_here&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;method_call&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run_experiment_kwargs&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;接下来是run_experiment_here函数，依然是只看重要一点的代码：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    &lt;span class=&quot;c1&quot;&gt;# 这个函数里只有一行代码：
&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# logger.reset()
&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# logger也是他们自己开发的，reset就是回归初始状态
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;reset_execution_environment&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# 这里做的事情包括：创建log目录，将variant参数记录下来，
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# 以及添加各式各样的路径和参数
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;actual_log_dir&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;setup_logger&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;exp_prefix&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exp_prefix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;variant&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;variant&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;exp_id&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exp_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;snapshot_mode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;snapshot_mode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;snapshot_gap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;snapshot_gap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;base_log_dir&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;base_log_dir&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;log_dir&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log_dir&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;git_infos&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;git_infos&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;script_name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;script_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setup_logger_kwargs&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# 启用seed
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;set_seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# 启用GPU，默认用id为0的GPU
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# 如果想选择用其他gpu，可以set_gpu_mode(use_gpu,gpu_id)
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_gpu_mode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;use_gpu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;run_experiment_here_kwargs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;variant&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;variant&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;exp_id&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exp_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;use_gpu&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;use_gpu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;exp_prefix&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exp_prefix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;snapshot_mode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;snapshot_mode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;snapshot_gap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;snapshot_gap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;git_infos&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;git_infos&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;script_name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;script_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;base_log_dir&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;base_log_dir&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setup_logger_kwargs&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# 把参数信息存成actual_log_dir下面的experiment.pkl文件
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;save_experiment_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;run_experiment_here_kwargs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run_experiment_here_kwargs&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;actual_log_dir&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# 好了，终于到我们的算法函数了。
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# 其实是这样的 grill_her_td3_full_experiment(variant)
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;experiment_function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;variant&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;接下来到这里：‍&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;grill_her_td3_full_experiment&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;variant&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# 看名字就知道功能了，预处理
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;full_experiment_variant_preprocess&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;variant&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# 训练vae，一边训练还会一边自己调参哦
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;train_vae_and_update_variant&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;variant&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# 这个看了再说。
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grill_her_td3_experiment&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;variant&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'grill_variant'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这篇先到这里吧，我累了&lt;img src=&quot;../assets/images/以图片为目标的视觉强化学习 -- 代码解析上篇(rlkit安装及部分代码及函数的解析和使用)/4.png&quot; style=&quot;zoom: 50%;&quot; /&gt;。下篇会讲具体模型算法还有训练测试代码，希望一个下篇就解决，不需要再分个中下&lt;img src=&quot;../assets/images/以图片为目标的视觉强化学习 -- 代码解析上篇(rlkit安装及部分代码及函数的解析和使用)/5.png&quot; style=&quot;zoom: 50%;&quot; /&gt;。&lt;/p&gt;

&lt;p&gt;感兴趣的小伙伴们就关注吧。觉得有用右下角帮忙点个赞哦。&lt;/p&gt;
</description>
        <pubDate>Tue, 08 Feb 2022 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/%E4%BB%A5%E5%9B%BE%E7%89%87%E4%B8%BA%E7%9B%AE%E6%A0%87%E7%9A%84%E8%A7%86%E8%A7%89%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0-%E4%BB%A3%E7%A0%81%E8%A7%A3%E6%9E%90%E4%B8%8A%E7%AF%87(rlkit%E5%AE%89%E8%A3%85%E5%8F%8A%E9%83%A8%E5%88%86%E4%BB%A3%E7%A0%81%E5%8F%8A%E5%87%BD%E6%95%B0%E7%9A%84%E8%A7%A3%E6%9E%90%E5%92%8C%E4%BD%BF%E7%94%A8)/</link>
        <guid isPermaLink="true">http://localhost:4000/%E4%BB%A5%E5%9B%BE%E7%89%87%E4%B8%BA%E7%9B%AE%E6%A0%87%E7%9A%84%E8%A7%86%E8%A7%89%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0-%E4%BB%A3%E7%A0%81%E8%A7%A3%E6%9E%90%E4%B8%8A%E7%AF%87(rlkit%E5%AE%89%E8%A3%85%E5%8F%8A%E9%83%A8%E5%88%86%E4%BB%A3%E7%A0%81%E5%8F%8A%E5%87%BD%E6%95%B0%E7%9A%84%E8%A7%A3%E6%9E%90%E5%92%8C%E4%BD%BF%E7%94%A8)/</guid>
        
        <category>Goal Directed Task</category>
        
        
        <category>Reinforcement Learning</category>
        
      </item>
    
      <item>
        <title>Facebook DeiT(Data-efficient Image Transformers) 解析</title>
        <description>&lt;p&gt;    今天看Facebook AI的DeiT。比起Moco v3训练出来的模型，DeiT胜在模型小，训练和推理都更加迅速。且精准度还有了很大提高。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/Facebook DeiT(Data-efficient Image Transformers) 解析/1.png&quot; style=&quot;zoom: 50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;    迅速到什么程度呢？用一个8-GPU服务器，训练3天就可以（其中预训练占用了53小时，fine-tuning占20个小时）。&lt;/p&gt;

&lt;p&gt;    看下图的效能比对，可以发现，DeiT确实是强悍的。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/Facebook DeiT(Data-efficient Image Transformers) 解析/2.png&quot; style=&quot;zoom: 50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;    接下来我们看DeiT的具体原理，首先，它的主干模型还是ViT，关于ViT可以看这篇：&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg5ODIwMTUxNw==&amp;amp;mid=2247484653&amp;amp;idx=1&amp;amp;sn=d490fc1c2f46d669de3419fa6fd7f89a&amp;amp;chksm=c067662ff710ef3970093452e7597825ed84c4c79d3cef931828ef62c0cf41d5b816fdb5fb5f&amp;amp;scene=21#wechat_redirect&quot;&gt;ViT (Vision Transformer)原理及代码解析&lt;/a&gt;，这里就不赘述了。&lt;/p&gt;

&lt;p&gt;    它可以训练的这么快的原因是用了&lt;strong&gt;蒸馏技术（distillation）&lt;/strong&gt;。 那什么是蒸馏技术呢？就是把一个模型的知识往另外一个模型迁移的过程。被迁移知识的那个模型，我们叫他teacher，是训练好的。从别的模型学到知识的模型，我们叫他student。通常是把大模型的知识往小模型上迁移。以期在不过分损失精准度的前提下，使推理速度大大提高。迁移的方式通常是让小模型和大模型有一样的输出。接下来看两种蒸馏方式：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;软蒸馏（soft distillation）&lt;/strong&gt;：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/Facebook DeiT(Data-efficient Image Transformers) 解析/3.png&quot; style=&quot;zoom: 67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;    Zt是teacher模型的输出，Zs是student模型的输出。ψ表示的是softmax，KL是KL散度（Kullback-Leibler），又叫相对熵，Lce是交叉熵（cross-entropy）。y是真实标签（ground truth label）。&lt;/p&gt;

&lt;p&gt;    这里参考&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg5ODIwMTUxNw==&amp;amp;mid=2247484059&amp;amp;idx=1&amp;amp;sn=422a4565edeba1b9087615ed0f72a59a&amp;amp;chksm=c0676059f710e94fe65e01143f15585b9ef1e7f46187f30a40fc5b9d6dd9c5bc38bddb2cf115&amp;amp;scene=21#wechat_redirect&quot;&gt;Cross Entropy Loss&lt;/a&gt;简单说一下KL散度和交叉熵的区别，这里就不上公式了，用大白话说，如果觉得有公式更容易理解，可以看参考文章中的公式。&lt;/p&gt;

&lt;p&gt;    首先说一下&lt;strong&gt;信息量&lt;/strong&gt;的概念，信息量指的是一个事件发生含的信息量，发生的概率越小，含的信息量就越大，比如太阳有天从西边升起来了，那么这个事件含的信息量就超级大了，全世界都得炸。而计算机里的信息量的大小指的是，描述一个事件发生所需要的位元（bits）。这里的描述和我们通常的语言描述是不一样的。而信息熵是信息量的期望值，还是太阳升起这个问题，它有可能从东边升起，也有可能从西边，南边，北边升起，虽然概率无限趋近于0，但是墨菲定律告诉我们，只要有概率，就一定会发生。那么太阳升起的方向这个事件有一个信息量的期望值，我们怎么理解期望值呢？太阳升起是从东南西北哪个方向呢，每个方向都会由一个概率，假设这件事情遵循特定的概率分布，如果这件事情发生无数次，那么平均每次我们需要用多少个位元来描述这件事情呢。平均每次，事件携带的信息量的大小，就是&lt;strong&gt;信息熵&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;    接下来我们解释&lt;strong&gt;相对熵&lt;/strong&gt;，也就是&lt;strong&gt;KL散度&lt;/strong&gt;。比如太阳升起是从东南西北哪个方向，假设这件事情遵循特定概率分布&lt;strong&gt;p&lt;/strong&gt;，假设我们不知道这个&lt;strong&gt;p&lt;/strong&gt;，现在我们自己估一个概率分布&lt;strong&gt;q&lt;/strong&gt;，是根据模型或者自己的认知设定的，那么用真实的概率分布会有一个信息熵，用我们估计的概率分布也会有一个信息熵，用估计的信息熵减去真实的信息熵，就是相对熵。相对熵计算的是，如果用我们估计的这个概率分布来替代真实的概率分布，如果这个事件会发生无数次，那么平均传输和描述这个事件需要多出多少位元。&lt;/p&gt;

&lt;p&gt;    而&lt;strong&gt;交叉熵&lt;/strong&gt;就是，如果用这个估计的分布替代真实的分布，如果这个事件发生无数次，平均需要多少位元来描述和传输这个事件。&lt;/p&gt;

&lt;p&gt;    这两个都可以用来比较两个分布的差异，差异越大，相对熵或者交叉熵就越大，差异越小，相对熵或者交叉熵就越小。&lt;/p&gt;

&lt;p&gt;    到这里我们来理解一下，为什么上面的公式，前面用的是交叉熵，后面用的是相对熵，因为前面y是固定的，不管我们怎么对样本进行变化，y都是不变的，因此由真实概率分布所得的信息熵是固定的，没有必要再去减一个固定值。但是后面的ψ(Zt/τ)则不一样了，如果我们用样本增强，或者我们不止有一个teacher，改变τ的值，那么ψ(Zt/τ)的值就会发生变化，信息熵也会发生变化，出于这种考虑，用相对熵保留差异部分可能可以更好的排除一些其他因素对loss造成的干扰。&lt;/p&gt;

&lt;p&gt;    当然，我这种理解不一定对。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;硬蒸馏 (hard-label distillation)&lt;/strong&gt;： &lt;/p&gt;

&lt;p&gt;    与软蒸馏不同的地方是，这里的yt是teacher的hard decision，yt = argmaxcZt(c)，也就是说yt不再是一个概率分布，而是一个根据最高概率做出的一个决策结果（但其实也可以看成一个概率分布，这里只是相对而言）。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/Facebook DeiT(Data-efficient Image Transformers) 解析/4.png&quot; style=&quot;zoom:50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;    与软蒸馏不同的，还有损失函数的选择。在硬蒸馏里，yt和y的关系是对等的，对结果起到的作用是对等的。大家会更偏好硬蒸馏，硬蒸馏参数更少，容易理解。这里的yt也会因为数据增强而产生不同结果，不是一定的。&lt;/p&gt;

&lt;p&gt;    接下来看，DeiT是怎么实现软硬蒸馏的。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/Facebook DeiT(Data-efficient Image Transformers) 解析/5.png&quot; style=&quot;zoom: 50%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;    在ViT的结构中，增加了一个和class token一样功能的distillation token。具体的代码实现可以看&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=Mzg5ODIwMTUxNw==&amp;amp;mid=2247484653&amp;amp;idx=1&amp;amp;sn=d490fc1c2f46d669de3419fa6fd7f89a&amp;amp;chksm=c067662ff710ef3970093452e7597825ed84c4c79d3cef931828ef62c0cf41d5b816fdb5fb5f&amp;amp;scene=21#wechat_redirect&quot;&gt;ViT (Vision Transformer)原理及代码解析&lt;/a&gt;，在一般的硬蒸馏里，用来和y计算差异的Zs和用来和yt计算差异的Zs是一致的，但是在DeiT里，分开了。&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# https://github.com/facebookresearch/deit/blob/main/models.py        
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;training&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;            &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# x是class token, x_dist是distillation token 
&lt;/span&gt;            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_dist&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# during inference, return the average of both classifier predictions
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;            &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_dist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;err&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;    根据DeiT模型里的代码，训练的时候返回的是cls_token，和distillation token，而在推理的时候，返回的是cls_token和distillation_token的均值。也就是说DeiT中的class token和distillation_token被认定有等价的推理价值。取均值会让推理更准确。&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# https://github.com/facebookresearch/deit/blob/main/losses.py    
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
        Args:
            inputs: The original inputs that are feed to the teacher model
            outputs: the outputs of the model to be trained. It is expected to be
                either a Tensor, or a Tuple[Tensor, Tensor], with the original output
                in the first position and the distillation predictions as the second output
            labels: the labels for the base criterion
        &quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;outputs_kd&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;isinstance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# assume that the model outputs a tuple of [outputs, outputs_kd]
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;            &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# class token，distillation token
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputs_kd&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;        &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# class token和groud-truth labels产生base loss
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;base_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;base_criterion&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;distillation_type&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'none'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;base_loss&lt;/span&gt;


        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputs_kd&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;raise&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;ValueError&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;When knowledge distillation is enabled, the model is &quot;&lt;/span&gt;
                             &lt;span class=&quot;s&quot;&gt;&quot;expected to return a Tuple[Tensor, Tensor] with the output of the &quot;&lt;/span&gt;
                             &lt;span class=&quot;s&quot;&gt;&quot;class_token and the dist_token&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# don't backprop throught the teacher
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;no_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;teacher_outputs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;teacher_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;distillation_type&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'soft'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tau&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# taken from https://github.com/peterliht/knowledge-distillation-pytorch/blob/master/model/net.py#L100
&lt;/span&gt;            &lt;span class=&quot;c1&quot;&gt;# with slight modifications
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;distillation_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kl_div&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log_softmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;outputs_kd&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                &lt;span class=&quot;c1&quot;&gt;#We provide the teacher's targets in log probability because we use log_target=True 
&lt;/span&gt;                &lt;span class=&quot;c1&quot;&gt;#(as recommended in pytorch https://github.com/pytorch/pytorch/blob/9324181d0ac7b4f7949a574dbc3e8be30abe7041/torch/nn/functional.py#L2719)
&lt;/span&gt;                &lt;span class=&quot;c1&quot;&gt;#but it is possible to give just the probabilities and set log_target=False. In our experiments we tried both.
&lt;/span&gt;                &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log_softmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;teacher_outputs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;reduction&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'sum'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;log_target&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputs_kd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;#We divide by outputs_kd.numel() to have the legacy PyTorch behavior. 
&lt;/span&gt;            &lt;span class=&quot;c1&quot;&gt;#But we also experiments output_kd.size(0) 
&lt;/span&gt;            &lt;span class=&quot;c1&quot;&gt;#see issue 61(https://github.com/facebookresearch/deit/issues/61) for more details
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;distillation_type&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'hard'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;distillation_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cross_entropy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;outputs_kd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;teacher_outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;argmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;


        &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;base_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;distillation_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;    看DeiT中的代码，软蒸馏和硬蒸馏都被定义了，inputs是样本，由teacher_model产生teacher_outputs，outputs中包含了class token和distillation token，class token和ground-truth label产生base_loss，而distillation token和teacher model产生的结果产生distillation_loss。&lt;/p&gt;

&lt;p&gt;    DeiT的原理大概说清楚了，实验的话，实在是懒，作者做了大量实验，如果想用DeiT，还是建议仔细看实验的。之后可能会写一篇，怎么用DeiT做分类和Transfer的文章。期待的话就关注吧。&lt;img src=&quot;../assets/images/Facebook DeiT(Data-efficient Image Transformers) 解析/6.png&quot; style=&quot;zoom:50%;&quot; /&gt;&lt;/p&gt;

</description>
        <pubDate>Tue, 23 Nov 2021 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/Facebook-DeiT(Data-efficient-Image-Transformers)-%E8%A7%A3%E6%9E%90/</link>
        <guid isPermaLink="true">http://localhost:4000/Facebook-DeiT(Data-efficient-Image-Transformers)-%E8%A7%A3%E6%9E%90/</guid>
        
        <category>Distillation</category>
        
        <category>ViT</category>
        
        
        <category>CV</category>
        
        <category>Representation Learning</category>
        
      </item>
    
  </channel>
</rss>
